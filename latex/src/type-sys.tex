\documentclass[droidmono,libertine,twoside,user,unofficial]{ecarticle}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage[tocgraduated]{tocstyle}
\usetocstyle{classic}

\usepackage{amsmath,amsfonts,amssymb}
\usepackage[english]{babel}

\usepackage[scale=0.85]{sourcecodepro}
\DeclareMathAlphabet{\mathtt}{T1}{SourceCodePro-TLF}{m}{n}
\usepackage{microtype}
\DisableLigatures{encoding = T1, family = tt* }

%\usepackage{pdfsync}
\usepackage{paralist}
\usepackage{proof}
\usepackage{listings}
\lstdefinelanguage{vtl}{%
  keywords=[1]{module,type,string,integer,float,number,boolean,date,%
    set,list,collection,any,none,null,define,function,new,as,is,%
    dataset,import,if,then,else,true,false,scalar,with,not,%
    data,structure,include,from,identifier,measure,attribute},%
  sensitive=false,%
  string=[d]{"},%
  morestring=[d]{'},%
  morecomment=[l]//,%by name
}
\lstset{%
  language=vtl,%
  basicstyle=\tt,%
  keywordstyle=\bfseries\color{black!66},%
  commentstyle=\itshape,%
  belowskip=\smallskipamount%
}

\usepackage{appendix}

\title{VTL 1.1 Core Proposal\\Revised Module And Type System}
%\subtitle{Follow-Up to the TF Meeting 3-4/12/2015}
%\date{June 17, 2016}

\author{D.I.}
%\eurolook{Version}{v0.1}
%\eurolook{Status}{}
\eurolook{Dissem}{Internal}
%\eurolook{UnitSuffix}{| Standards and tools}

\usepackage[rounded]{syntax}
\def\<#1>{\synt{#1}}
% \usepackage{oz}

\usepackage[parfill]{parskip}

\usepackage{mathabx}

\newcommand{\nm}[1]{\ifmmode\mathsf{#1}\else\textsf{#1}\fi}
\newcommand{\kw}[1]{\ifmmode\mathtt{#1}\else\texttt{#1}\fi}
\newcommand{\angled}[1]{\ensuremath{\left\langle#1\right\rangle}}

\newcommand{\nonterm}[1]{\synt{<#1>}}

\newcommand{\denot}[1]{\ensuremath{\ldbrack#1\rdbrack}}

\newcommand{\grule}[2][]{%
  %\href{run:vtl-1.1-core-grammar#1.html}{\synt{#2}}%
  \href{run:./vtl-1.1-core-grammar.xhtml}{here}%
}

\newtheorem{definition}{Definition}

\newcommand\Gr[2]{\rlap{\color{red}#1#2}#2}

\newcommand{\optSemiCol}{\begin{stack}\\`;'\end{stack}}

\newcommand{\tpar}[1]{%
	\ifmmode%
%		\text{\tt<}#1\text{\tt>}%
        \langle#1\rangle%
	\else%
		\texttt{<}#1\texttt{>}%
	\fi%
}

\newcommand{\tvar}[1]{%
  \ifmmode%
  \text{\tt?#1}%
  \else%
  \mathtt{?#1}%
  \fi%
}

\newcommand{\tbot}{%
  \ifmmode%
  \text{\tt()}%
  \else%
  \texttt{()}%
  \fi%
}

\DeclareMathOperator\obj{obj}

\newcommand{\ilbl}[1]{\ifmmode\text{\textsc{#1}}\else\textsc{#1}\fi}

\begin{document}

\maketitle

% ===================================================================

\section{Introduction}
\label{sec:introduction}

In VTL 1.1, the type system has to significantly evolve in comparison
to the version 1.0 in order to express not only the rich data model,
but also different kinds of new objects (such as rules and rule sets),
functions, and modules, which were not prominent in the version 1.0 of
the language.  Added to it is the need for a simple, yet effective
module system, which allows modularisation and versioning of both
user-defined and persistent objects.

To accomplish its task, the new module and type system for VTL 1.1
needs to be carefully motivated and engineered to ensure, on the one
hand, sufficient expressiveness, and on the other hand logical
coherence and desirable properties expected of modern and reasonably
well-designed computer languages.  At the same time, these new systems
should be reasonably easy to support in various VTL implementations,
which may be based on different concrete information models and
persistent data stores.

In this document, we present the fundamental elements of the
motivation and the structure upon which the type system for VTL 1.1 is
built.  We first give an outline of the module system, and present the
type system step-by-step, starting from the simpler and going towards
more complex types.

% To accommodate within the same coherent framework the rich information
% model for VTL 1.1, as well as a growing number of new objects, including the
% horizontal, vertical, and other kids of rules, the type system for VTL
% 1.1 needs to significantly evolve compared to the one in VTL 1.0.
% %
% This new type system needs to be carefully engineered to ensure not
% only good coverage of the VTL language and IM artefacts, but also
% its internal conceptual and algebraic simplicity and coherence.  It
% is therefore important to motivate the type system correctly and
% choose a correct paradigm on which to build.



% the structure and the structural constraints (such as code lists) of
% datasets that are fed to or returned from VTL programs.  Therefore, it
% is closely related to the external representation of these inpataseuts
% and outputs.
% %
% The type system, on the other hand, is concerned with typifying all
% tnds of objects that may appear (or be possibly constructed) at any
% stage of execution of a valid VTL program.  These objects need to
% include those described in the information model, but there are many
% other kinds of objects (such as function abstractions) that arise from
% the internal structure and logic of the language, that cannot be (and
% are not meant to be) treated by the information model.

% Another way to highlight the distinction between the VTL information
% model and the VTL type system is to point out how the two relate to
% the syntax and semantics of the language:
% %
% \begin{itemize}

% \item The information model has a fixed structure expressed in an
%   abstract, programming language independent manner, usually through
%   UML diagrams or equivalent descriptions.  This is because we want to
%   facilitate interoperability with as many external systems as
%   possible.  The central concern of the information model is
%   interoperability, not the internal functioning of VTL.  As a
%   consequence, the information model is essentially independent from
%   the syntax and semantics of VTL.  In fact, one can build many
%   different validation and transformation languages, widely differing
%   in syntax and semantics, on top of the VTL information model.

% \item In contrast, the type system forms an integral part of the VTL syntax and
%   semantics.  Its main concern is organizing all objects that can be
%   encountered in the course of execution of a legal VTL program in a
%   coherent hierarchy.  The role of the type system at compile time is
%   to assist in the static analysis of a VTL program, and to find out
%   what kind of objects will be encountered in each operation, so that
%   the correct (and possibly optimised) executable code is produced.
%   Also, the type system may help detect numerous errors at compile
%   time, before the program is deployed and run.

% \end{itemize}

% Both the VTL information model and the VTL must be carefully designed,
% and care has to be taken to make the two mutually interoperable.

% In this document, we propose the syntax and semantics for the VTL type
% system.  In the proposed design, VTL is a strongly typed language,
% although explicit typing is optional and normally unnecessary.  This
% means that the type of each expression and sub-expression in VTL is
% known at compile time.  With this information, the compiler can
% enforce type safety, i.e., it can make sure that the language
% functions and operations always receive inputs and return outputs that
% are of right kind and complete.  With type safety, the compiler can
% detect a wide range of errors or potential problems before the program
% is sent for execution.  This is highly desirable for a validation
% language, because potential errors in a validation program may lead to
% its wrong behavior and bring the validation results in question.

% However, the VTL type system also includes the key elements of
% manifest typing and type reification.  Every object is equipped with
% run-time type information describing its actual type.  It is therefore
% possible to use introspection in order to inspect the structure and
% the content of an object at run-time.  Also, the types defined inside
% a program are also represented by objects at run-time.  That allows us
% to access precise types of, for instance, column types in a dataset
% structure, although these are necessarily generalised by the type
% system.


\section{A brief outline of the module system}
\label{sec:brief-intr-module}

VTL 1.1 code does not have to be grouped all together in a single
program file, but can be divided into several modular units that can
be maintained separately and combined together as necessary.  These
units are called modules.

VTL 1.1 has two kinds of program units -- main programs and modules --
which are normally stored in separate files, or comprise separate
electronic documents exchanged between services and/or registries.
%
As we shall see, modules can be user-defined or virtual.

Introduction of modules in VTL 1.1 is motivated by the following
concerns:
\begin{itemize}
\item Except for very small programs, without modules it becomes
  necessary to put all elements required for the execution of a
  validation or transformation program into a single, long, monolithic
  program.  While some of required objects may be stored in a
  persistent store, and are therefore readily available to the
  program, others would need to be re-implemented in each program.
  This makes program long and leads to maintainability issues.

\item To simplify the task of writing validation and transformation
  programs, and to improve their correctness and maintainability,
  statistical organisations would naturally tend to create libraries
  of VTL code for different processing purposes.  Modules are natural
  vehicles for organising and storing such libraries.  Furthermore,
  statistical organisations may want to exchange their libraries and
  use standard libraries developed by other organizations, including
  the coordinating bodies that are in charge of defining the standard
  validation rules for certain domains. The proposed solution in VTL
  are \emph{user-defined modules}, described below.
  
\item Even for objects that are stored in a persistent storage, e.g.,
  those corresponding to the structural metadata and validation rules,
  in real world situations we want to maintain different versions in
  parallel and to be able to apply correct validation and
  transformation rules to each dataset depending on the context
  factors such as the dataset reference period or area.  This calls
  for having several packages (i.e., modules) containing named
  objects.  Then, the programs can choose which packaged module to
  apply depending on the business rules.  The proposed solution for
  VTL are \emph{virtual modules}, described below.
\end{itemize}

\subsection{User-defined modules}
\label{sec:user-defined-modules}

User defined modules are written by a programmer and are distinguished
by starting with the module declaration:
\begin{syntdiag}
  `module' <IDENT> \optSemiCol
\end{syntdiag}

An example would be:
\begin{lstlisting}
module PopulationModel

type Sex = string {"M", "F"} // A codelist

define data structure PopulationStruct(
  // Component specifications
)

define function process(ds as dataset) as dataset {
  // Computation steps
}

Pi := 3.1415926536   // A constant

// More definitions inside the module
// until the end of file.
\end{lstlisting}

Each user-defined module defines and names different kinds of things,
such as user-defined types, functions, data structures, constants etc.
%
All names (i.e., identifiers) defined in the module must be mutually
distinct.  It is an error to try to define the same name twice.
Publicly visible names are all that do not begin with an underscore
(\lit{\_}).

\subsection{Importing a user-defined module}
\label{sec:importing-module}

When a main program or another module want to indicate a dependency on
another module, they need to use the \lit{import} statement.  Its
simplest form is:
\begin{syntdiag}
  `import' <IDENT> \optSemiCol
\end{syntdiag}

This statement tells the VTL processor to find the module whose name
is \<IDENT> and make it available to the current program unit (the
main program or another module).  Circular dependencies between
modules are not allowed: if module A imports module B, B cannot import
A either directly or transitively via some other module C.

It is up to the VTL implementation to decide where to look for a
user-defined module.  Typically these should are stored in some kind
of system-wide register, e.g., in a directory with source and compiled
files whose names correspond to modules names.

After \lit{import ABC}, all public names defined in module
\texttt{ABC} (i.e., those not starting with an underscore) become
visible in the current program scope.
%
If we want to import just several specific names, say \lit{ABC} and
\lit{XYZ} from module named \lit{MOD}, we use the form:
\begin{syntdiag}
  `import' <IDENT> `::' `{'
    \begin{stack}
      \\
      \begin{rep}
        <IDENT> \\ `,'
      \end{rep}
    \end{stack}
    `}' \optSemiCol
\end{syntdiag}
and write:
\begin{lstlisting}
import MOD::{ABC, XYZ}
\end{lstlisting}

In this case only the names \lit{ABC} and \lit{XYZ} from \lit{MOD}
become visible in the current scope, while we have to write
\lit{MOD::DEF} to refer to name \texttt{DEF} defined in \lit{MOD}.

In a special case, we can write:
\begin{lstlisting}
import MOD::{}
\end{lstlisting}
if we just want to import module \lit{MOD}, but do not want to
automatically import any of its members (e.g., because their names may
clash with other imported names).

\subsection{Name conflicts in module imports}
\label{sec:name-confl-module}

When we have several imports that define the same name, the definition
from the last import is visible in the current program scope.  A VTL
processor may issue a warning indicating that a definition from a
later import hides a name defined in an earlier import.


\subsection{Sub-modules}
\label{sec:sub-modules}

Sometimes it is handy to further sub-divide a user-defined module to
contain sub-modules.  One example would be:
\begin{lstlisting}
// File: module_a.vtl
module A

types := new module {
  type return_code = integer {-1,0,1}
  type country_code = string[2]
  type confidentiality_level = string { "PUB", "EMB", "CONF" }
  // Other type definitions
}

datasets := new module {
  define dataset sample1(
    // ...
  )
 // More datasets and data structures
}

constants := new module {
  Pi := 3.1415925536
  EstatName := "European Statistical Office (ESTAT)"
  // More constants
}

// Other definitions until the end of file
\end{lstlisting}

We can then access members of \texttt{A} as
\texttt{A::types::return_code},
\texttt{A::datasets::sample1}, or \texttt{A::constants::Pi}.

If we put the following statements at the end of module \texttt{A}:
\begin{lstlisting}
include types
include datasets
include constants
// Etc.
\end{lstlisting}
then all components from these sub-modules will become visible as if
they were directly defined in module \texttt{A}.  However, the
compiler will signal an error if there are any overlaps in names
between the names in the included modules and other members directly
defined in \texttt{A}.

\subsection{Virtual modules}
\label{sec:virtual-modules}

In many cases, objects such as the Information Model artefacts are be
stored in a persistent data store, typically a database attached to
the VTL processing system, or stored in metadata registries.  These
objects also need to be made available to the VTL runtime system in
the same way as the objects defined in the user-defined modules. This
is done using \emph{virtual modules}, which can be thought of as
module views of these persistent artefacts.

To import such a module we use the \lit{import ... from} syntax:
\begin{syntdiag}
  `import' <IDENT>
  \begin{stack}
    \\
    `::'
    `{'
      \begin{stack}
        \\
        \begin{rep}
          <IDENT> \\ `,'
        \end{rep}
      \end{stack}
      `}'
  \end{stack}
  `from' <package-id> `:' <agency-id> `:' <version>
  \optSemiCol
\end{syntdiag}
\begin{center}\small
  \begin{tabular}{ccc}
      \<package-id> ::= \<string-literal>
    &
      \<agency-id> ::= \<string-literal>
    &
      \<version> ::= \<string-literal>
  \end{tabular}
\end{center}

For instance:
\begin{lstlisting}
import InfoModel::* from "NAPS":"ESTAT":"1.4"
\end{lstlisting}
imports the virtual module named \lit{InfoModel} from package named
\texttt{"NAPS"} owned by agency \texttt{"ESTAT"}, version
\texttt{"1.4"}.

% ...................................................................
\subsection{Virtual module loading strategy}
\label{sec:virt-model-load}

Each VTL implementation, depending on the underlying data store
architecture and/or the concrete metadata model, can define its own
way of resolving the imported module name, package and agency
identifiers, and version numbers into a virtual module whose content
is imported.  Some potential approach that can be used or mixed
together include the following:
\begin{itemize}
\item Virtual VTL modules contain artefacts stored in a relational
  database.  Package and agency identifiers are mapped to
  database/schema names.  Entities in the database tables are
  versioned and matched against the given version number.  For each
  schema there is a number of fixed module names, e.g.:
  \begin{compactenum}[--]
  \item \texttt{InfoModel} contains dataset structure and dataset
    definitions, and other relevant structural artefacts.
  \item \texttt{Rules} contains various validation rules.
  \item \texttt{Utilities} contains various validation functions,
    constant definitions and other utilities.
  \item \texttt{All} is the meta-package that includes all of the
    individual packages listed above.
  \end{compactenum}
\item Virtual VTL modules contain artefacts defined in structural SDMX
  metadata stored in a registry.  Entity identifier, package
  identifier and version are used to retrieve the structure file from
  a SDMX registry.  Package names are also predefined as in the
  previous case.
\end{itemize}

% ...................................................................
\subsection{Standard virtual module names and automatic loading}
\label{sec:virt-module-autol}

Several virtual module names have special meanings:
\begin{itemize}
\item \texttt{InfoModel} contains the definition of represented
  variables, value (sub-)domains, dataset structures and datasets.
  
\item \texttt{Rules} contains the definition of validation rules.
\end{itemize}

Each VTL program runs in a \emph{default context} defined as a triplet
of \<package-id>, \<agency-id> and \<version>.  This context may be
implicit in the particular VTL system instance, or may be specifically
requested by the user before a program is run.

The above mentioned special modules \texttt{InfoModel} and
\texttt{Rules} are automatically imported by the system before
compiling / executing the program, exactly as if the following two
import statements:
\begin{lstlisting}
import InfoModel from "<package-id>":"<agency-id>":"<version>"
import Rules from "<package-id>":"<agency-id>":"<version>"
\end{lstlisting}
appear at the program start:

% ...................................................................
\subsection{Sharing virtual modules}
\label{sec:shar-virt-modul}

While sharing user-defined VTL modules is just a matter of sharing
module source files, virtual modules reside natively in a persistent
store.  Nevertheless, it is often useful to generate a VTL source code
of a virtual module in order to share it between systems and
organisations that may use entirely different persistent store
architectures, e.g., relational databases vs.\ SDMX repositories.

For that, VTL implementations must include tools that generate
shareable VTL source code from the name, package and agency
identifiers and the version number of a persistent module.  These
source files look exactly the same as the user-defined modules, except
that they use \lit{module... from} syntax:
\begin{syntdiag}
  `module' <IDENT> `from' <package-id> `:' <agency-id> `:' <version>
  \optSemiCol
\end{syntdiag}
For instance:
\begin{lstlisting}
module InfoModel from "NAPS":"ESTAT":"1.4"
// Definitions of various information model artefacts
\end{lstlisting}

Conversely, VTL compiler or another tool must be able to take the
source code representation of a virtual module that uses
\lit{module... from} syntax and create from it the corresponding
artefacts in the underlying system-specific persistent store.


\section{Main properties of the type system}

The basic role of the type system is to organize all possible objects
that may appear during the execution of a syntactically and
semantically valid VTL program (as inputs, parameters, data
structures, results of intermediate computation steps, or the final
results) into a well-defined hierarchy, also known as the \emph{type
  lattice} (discussed later).

In this document, we use the word ``object'' to refer to a runtime
(typically, in-memory) representation of a scalar VTL value (such as a
number or a character string), or of a complex entity (such as a
dataset, a function, or a module).

A \texttt{type} is the information used by the VTL compiler and the
run-time system to describe an object:
\begin{itemize}
\item At compile time, the compiler analyzes the program and assigns
  type to all user-defined and built-in names describing what kind of
  object they refer to (scalars, datasets, functions, rules, etc.).
  Then, the compiler uses this information to infer type of each
  elementary and complex expression in the program.  Based on this,
  the compiler enforces type safety (see the next subsection).
  
\item At run-time, each object carries the run-time type information
  describing it.  The run-time system uses this information to handle
  the object correctly, and, when necessary, to perform run-time type
  checking (e.g., checking that an object known at compile time to be
  scalar is in fact at a number at run-time). 
\end{itemize}

It is important to have in mind the following points on the type
system:
%
\begin{itemize}

\item It must have 100\% coverage of all possible runtime objects.  In
  other words, each possible object must belong to a type.

\item An object may belong to more than one type.  For instance, in
  VTL a character string belongs to types \texttt{string},
  \texttt{scalar} (covering all scalar values), and \texttt{any}
  (covering all possible objects). However, when we are speaking of
  the object's type, we are normally referring to the type that
  provides the most precise information about the object (in our
  example, that is \texttt{string}).  \footnote{As an exception from
    this rule, some programming languages such as Java, allow one
    special value \lit{null} to belong to \emph{all} object types.
    However, \lit{null} is normally not taken as a legal object as
    such.  Value \lit{null} is treated differently in VTL 1.1.}

%However, there must exist exactly one type that describes the object most precisely.%

%For instance, in VTL the character string \texttt{"abc"} belongs to the following types (among others):
%\begin{compactitem}[-]
%\item \texttt{string\{"abc"\}}: the type of character strings with the exact value \texttt{"abc"};
%\item \texttt{string\{"a", "abc", "de"\}}: the type of character strings having one of the three values enumerated inside the curly braces;
%\item \texttt{string[3]}: the type of character strings with exactly three characters;
%\item \texttt{string[2:5]}: the type of character strings with between two and five characters;
%\item \texttt{string}: the type covering all possible character strings;
%\item \texttt{scalar}: the type covering all possible scalar values, including character strings; and
%\item \texttt{any}: the type covering all possible objects, including scalars.
%\end{compactitem}
%%
%However, it is clear that type \texttt{string\{"abc"\}} describes the string literal \texttt{"abc"} most precisely.

\item Each type implies a finite or infinite set of objects that
  belong to it.  In VTL 1.1, given an object and a type, it is
  possible to check at run time whether that particular object belongs
  to that particular type.%
  \footnote{This is possible in VTL, Java, etc., which include the
    runtime type information for all objects, but not always in all
    programming languages, e.g. in C.}
  %
  At compile time, the type checker is able to detect cases where a
  runtime object cannot possibly belong to a type.
\end{itemize}

\subsection{Static analysis and type safety}

Static analysis is a common name for a wide spectrum of automatic
analyses performed by a compiler (or a separate code analysis tool).
It looks at VTL code and reasons about its runtime behavior without
actually executing it.  If static analysis detects a potential problem
in VTL code which may cause it to misbehave at runtime, the program
can be marked as \textit{unsafe}, and, depending on the severity of
the problem, an error or a warning can be reported.

Type analysis, or type checking, is one of the classical static
analyses, and is very important in VTL.  The fundamental task of type
analysis is check that all variables and expressions in the program
produce objects that belong to the expected type.  In other words,
type analysis aims at preventing runtime type errors, which occur when
an object of a wrong type is encountered, for instance a string
instead of a number, or a list in place of a dataset.

Programs that successfully pass type analysis are called type safe.
In a validation language such as VTL, type safety is essential because
it prevents many potential runtime errors that may be
hard to trace (especially in a service oriented, non-interactive usage
scenario) and, from the point of the end user, indistinguishable from
a validation error.

By its nature, static analysis relies on a safe approximation of the
program runtime behavior.  This means that in some cases potential
problems detected by static analyzers do not \emph{necessarily} need
to happen each time the program is run, or indeed ever.  The better a
static analyzer is engineered, the smaller is the number of such false
positives.  But the most important thing for the static analyzer is to
err only on the safe side, and not fail to detect a potential problem.


\subsection{Typing discipline}
\label{sec:typing-discipline-1}

To ensure type safety, VTL 1.1 imposes a strong typing discipline
which is based on mostly optional type annotations and type inference,
based on a variant of Hindley-Milner type inference algorithm.

This means that the types of most variables and other objects in a VTL
program do not need to be explicitly given in the code, but are
inferred automatically by the compiler.  When such an inference is
impossible (as in some cases when the compiler cannot infer the return
type of a function), a type error requiring explicit type annotation
is issued by the compiler.


\subsection{Relationship with the module system}
\label{sec:relat-module-syst}

Modules are the main tool for organizing VTL code in units instead of
heaping up all objects and definitions in a single crowded namespace.

As in many modern functional and object-oriented programming
languages, there is an intimate relationship in VTL 1.1 between the
module system and the type system.  The latter includes \emph{module
  types} (cf.\@ page \pageref{sec:module-types}) which directly module
the structure of a program module, but are applicable also for
modeling ``smaller'' objects, analogous to Java objects.


\subsection{Relationship with the VTL Information Model}

The VTL type system and the VTL Information Model (IM) are related,
but serve distinct purposes.

The IM defines entities (artefacts) that are comprise the VTL's
application domain, namely the datasets, their structures, and related
statistical notions that figure in the field of statistical data
validation.  Entities modeled as the IM artefacts are those that are
meaningful for the user (the statistician) as inputs and outputs of a
VTL program, and are normally externally representable in some kind of
a persistent store.  The IM artefacts ``exist'' even when VTL programs
are not running.  Since the actual implementation of the IM depends on
the persistence technology, it is described conceptually, using UML
diagrams.

On the other hand, the type system needs to support all possible
objects that can be processed by a VTL program at run-time, whether or
not these object directly correspond to an IM artefact.  Of course,
the type system needs to provide a vocabulary for supporting all IM
artefacts, but beside that, it is not difficult to find an example of
objects that may be useful in VTL programs even though they are not
included in the IM.
%
For instance, a VTL function that computes a histogram of a dataset
may use a list of pairs where the first component in each pair is a
string, and the second component is an integer.  Clearly, the type
``list of (string, integer) pairs'' is not in the IM.  It can be
included, but then one can think of an infinite number of similar
\emph{auxiliary} objects, which are useful for, e.g., implementing
various algorithms, but may not be meaningful, as such, in the IM
context.

Of course, it would be possible, at least in principle, to extend the
IM to include all kinds of these auxiliary objects that may be used by
programmers in one case or another, but this approach has few
important drawbacks:
\begin{itemize}
\item The IM complexity grows significantly.  In the end it starts to
  approach the meta-model complexity of a subset of UML.
\item Adding auxiliary objects to the IM would obscure the focus of
  the IM, which is based on a simplified version of the GSIM IM.
\item Requiring all runtime objects to be covered by the IM means
  anticipating 100\% the needs and the ideas by the programmers, and
  restricting their choice in the future.
\item Requiring all objects to have their IM representation may
  complicate the compiler, in the sense that there are legal VTL
  expressions that may foresee something that has not been foreseen in
  the model (e.g., a triple consisting of a dataset, an integer, and a
  function).
\end{itemize}

An alternative approach would be to keep the IM concentrated on the
essential artefacts that are relevant for the domain of statistical
validation, and then make sure that the type system is expressive
enough to can appropriately model the artefacts of the IM.
%
The advantage of this solution is that we can follow the road which is
more traditional in the type system design:
\begin{itemize}
\item Using as the base the types for modeling scalar data: numbers,
  strings, Booleans, and dates, including the numbers and string
  constrained to value/size or an enumeration of values (i.e., string
  and numeric code lists).
  
\item Using generalised Cartesian product and collection types (lists
  and sets) over arbitrary element types, as the basic building blocks
  for algorithmic data structure.
  
\item Using the dedicated dataset types to describe datasets, as the
  key ingredient of the IM.

\item Using module types, as a lightweight object abstraction, to
  model other complex artefacts from the IM.  The module types are
  simple abstraction of the class boxes from the UML diagrams, and
  therefore can be used to model all artefacts.
\end{itemize}


% ===================================================================

\section{Informal step-by-step type system introduction}
\label{sec:type-system-syntax}

In this section, we present the syntax of VTL types, together with an
informal description of the intended meaning of different constructs.
We start from a basic, simple grammar for concrete data, which we then
gradually expand.

To present the concrete type grammar, we use the syntax (or railroad)
diagrams, rather than the ``raw'' EBNF production rules. However, the
converting the syntax diagrams into EBNF production rules is a
straigtforward exercise.  Whenever we extend the syntax, we mark the
new syntax elements in the diagrams by typesetting them in boldface.
When writing various type forms in text, we use the monospaced font
for concrete syntactic elements, and italicised letters, such as $t$,
$u$, $v$, etc. (possibly with subscripts or supercripts) as
placeholders.  To give a simple example, \lit{set<$t$>} is a syntactic
form where $t$ is a placeholder for the set element type.

\begin{figure}[t]
%  \centering
  % \begin{grammar}
  %   <type> ::= <fun-type> | <prod-type>

  %   <fun-type> ::= <prod-type> `->' <type>

  %   <prod-type> ::= <type-factor> `*' <product-type> | <type-factor>

  %   <type-factor> ::= <scalar-type>
  %   \alt <collection-type>
  % \end{grammar}

  \<type> ::=
  \begin{syntdiag}
    <type-factor>
  \end{syntdiag}

  \<type-factor> ::=
  \begin{syntdiag}
    \begin{stack}
      <scalar-type>
      \\
      <collection-type>
      \\
      <dataset-type>
    \end{stack}
  \end{syntdiag}

  \<scalar-type> ::=
  \begin{syntdiag}
    \begin{stack}
      `number'
      \\
      `integer'
      \\
      `float'
      \\
      `boolean'
      \\
      `date'
      \\
      `string'
    \end{stack}
  \end{syntdiag}

  \<collection-type> ::=
  \begin{syntdiag}
    \begin{stack}
      `set' \\ `list'
    \end{stack}
    `<' <scalar-type> `>'
  \end{syntdiag}

  \<dataset-type> ::=
  \begin{syntdiag}
    `dataset'
    \begin{stack}
      \\
      <struct-spec>
    \end{stack}
  \end{syntdiag}

  \<struct-spec> ::=
  \begin{syntdiag}
    `{'
        \begin{rep}
%          <role>
          \begin{stack}
            `measure'
            \begin{stack}
              `_'
              \begin{stack}
                `*' \\ `+'
              \end{stack}
              \\
              <IDENT>
            \end{stack}
            \\
            \begin{stack}
              `identifier' \\ `attribute'
            \end{stack}
            <IDENT>
          \end{stack}
          `as' <scalar-type>
          \\
          `,'
        \end{rep}
        \begin{stack}
          \\
          `...'
        \end{stack}
      `}'
  \end{syntdiag}

  % \<role> ::=
  % \begin{syntdiag}
  %   \begin{stack}
  %     `identifier' \\ `measure' \\ `attribute'
  %   \end{stack}
  % \end{syntdiag}

  \caption{The starting point for the type grammar.}
  \label{fig:basic-type-grammar}
\end{figure}

\subsection{The starting point}
\label{sec:basic-concr-type-grammar}

Figure~\ref{fig:basic-type-grammar} gives our starting point.  It is a
simple grammar for the basic concrete types that reflect the essential
structure of dataset section in the VTL information model, plus the
collections (lists or sets) of scalars.
%
This basic type system is very close to the one described in the
documentation for VTL 1.0.  The top level syntactic element is
\<type>.  In the reminder of this document, when we say \emph{type},
we mean a syntactically valid finite expansion of this non-terminal
symbol.  The same approach is used for scalar types, dataset types,
collection types, etc.
%
In this first step, \<type> is a synonym for \<type-factor>,
but that will change as we extend the type system in the steps that
follow.

For the start, a \<type-factor> can be one of following things: a
scalar type, a list or a set of scalars, or a dataset type.  We treat
each of these cases in turn.

\subsection{Basic scalar types and their collections}
\label{sec:basic-scalar-types}

The scalar types are shown in Figure~\ref{fig:basic-type-grammar} and
include:
\begin{itemize}
\item Numbers (type \texttt{number}), which are internally sub-divided
  in integers (type \texttt{integer}) and floating-point numbers (type
  \texttt{float}).

\item Boolean values (type \texttt{boolean}), which can be either
  \texttt{true} or \texttt{false}.\

\item Character strings (type \texttt{string}), consisting of zero or
  more Unicode characters.

\item Timestamps containing date and optionally time information (type
  \texttt{date}.
\end{itemize}

Types \texttt{list<$t$>} and \texttt{set<$t$>}, where $t$ is a scalar
type, represent finite (possibly empty) lists and sets of elements of
type $t$.

% \paragraph{Compile-time typing and run-time type information.}

% Type of a variable or an expression reflects the static, compile-time
% knowledge about the object.  For instance, if the type is
% \texttt{number}, that means that at compile time we accept both
% integers and floating point numbers, and, to take another example, if
% the type is \texttt{dataset} (without \<struct-spec>), that means that
% any dataset is accepted.
% %
% However, at runtime each object has a concrete, precise type attached
% to it.  So, an object whose compile-time type is \texttt{number} is at
% runtime either an \texttt{integer} or a \texttt{float}.  Likewise, any
% object whose compile-time type is \texttt{dataset} (without
% \<struct-spec>) carries at runtime a \texttt{dataset} type with the
% precise actual structure included.

% It is worth noting that when a dataset type does not specify the
% dataset structure, or when it does it only partially, that does not
% mean that the actual structure of a dataset instance is unknown or
% partially specified at run-time. Simply, the dataset structure in type
% system represents the static (i.e, compile-time) knowledge of the VTL
% system (specified by a programmer or inferred by the compiler) about
% what is expected at runtime.  For instance, one can write a
% user-defined function that accepts a dataset and looks at the number
% of rows inside it. From the point of view of the type system, the type
% of the dataset parameter is simply \lit{dataset}, with no structure
% specification.

% ...................................................................

\subsection{Dataset types}
\label{sec:dataset-types}

Figure \ref{fig:basic-type-grammar} also includes the dataset types.
%
The most general case is simply \lit{dataset}, which includes all
possible datasets, whatever their structure may be.  Optionally, we
can completely or partly specify the dataset components inside curly
braces.  Each component is specified through its role
(\lit{identifier}, \lit{measure} or \lit{attribute}), name, and the
scalar data type.  Component names are unique within a dataset.  If
the specification within curly braces includes \lit{...}, that means
that the specification is partial, i.e., a concrete dataset
corresponding to this type may contain other components not listed.

The exception from this rule is the specification for measure
components using an (unquoted) underscore instead of the concrete
measure component name, which has a special meaning.  For instance,
\begin{lstlisting}
measure _ as number
\end{lstlisting}
requires the dataset to have exactly one measure component of type
\texttt{number} (i.e., to be a mono-measure dataset).
% %
% If we quote the underscore, as in:
% \begin{lstlisting}
% measure '_' as number
% \end{lstlisting}
%
This restriction is absolute if the specification is partial, i.e., if
it ends with \lit{...}.  For instance, type:
\begin{lstlisting}
dataset {
  measure _ as number,
  attribute obs_status as string [0:10] ...
}
\end{lstlisting}
describes a class of datasets, at least one string attribute named
\lit{obs\_status}, and any number of identifiers and additional
attributes.


%
We can also use the following variations:
\begin{center}
  \begin{tabular}{l|l}
    \textbf{Syntax}
    & \textbf{Meaning}
    \\\hline
    \texttt{measure \_ as $t$}
    &
      Exactly one measure of type $t$
    \\
    \texttt{measure \_* as $t$}
    &
      Zero or more measures, all must have type $t$
    \\
    \texttt{measure \_+ as $t$}
    &
      One or more  measuresl, all must have type $t$
    \\\hline
  \end{tabular}
\end{center}

When a dataset type specifies one or more dataset components, it
covers all datasets that have these components and possibly some
others.  Components of a dataset type instance must have types that
are compatible with the types given in the specification, but the
roles must be the same.  E.g., if the dataset type specification has
\texttt{measure population as number}, then the actual dataset
instance can have \texttt{measure population as integer} or
\texttt{measure population as float}.

% ...................................................................

\subsection{Constrained scalar types}
\label{sec:constrained-scalar-types}

\begin{figure}[t]
%  \centering

  \<scalar-type> ::=
  \begin{syntdiag}
    \begin{stack}
      `number'
      \\
      `integer'
      \begin{stack}
        \\
        `\bfseries['
        \begin{stack}
          <\bfseries int-literal>
          `\bfseries :'
          \begin{stack}
          \\
          <\bfseries int-literal>
          \end{stack}
          \\
          `\bfseries :' <\bfseries int-literal>
        \end{stack}
        `\bfseries]'
        \\
        `\bfseries {' \begin{rep} <\bfseries int-literal> \\
            `\bfseries ,' \end{rep} `\bfseries }'
      \end{stack}
      \\
      `float'
      \begin{stack}
        \\
        `\bfseries['
        \begin{stack}
          <\bfseries float-literal>
          `\bfseries :'
          \begin{stack}
          \\
          <\bfseries float-literal>
          \end{stack}
          \\
          `\bfseries :' <\bfseries float-literal>
        \end{stack}
        `\bfseries]'
        \\
        `\bfseries {' \begin{rep} <\bfseries float-literal> \\
            `\bfseries ,' \end{rep} `\bfseries }'
      \end{stack}
      \\
      `boolean'
      \begin{stack}
        \\
        `\bfseries {'
          \begin{rep}
            \begin{stack}
              `\bfseries true' \\ `\bfseries false'
            \end{stack}
            \\
            `\bfseries,'
          \end{rep}
          `\bfseries }'
      \end{stack}
      \\
      `date'
      \\
      `string'
      \begin{stack}
        \\
        `\bfseries [' <\bfseries nat-literal>
        \begin{stack}
          \\
          `\bfseries :' <\bfseries nat-literal>
        \end{stack}
        `\bfseries ]'
        \\
        `\bfseries {'
          \begin{rep}
            <\bfseries string-literal>
            \\
            `\bfseries ,'
          \end{rep}
          `\bfseries }'
      \end{stack}
    \end{stack}
  \end{syntdiag}

  \caption{Introducing constrained scalar types.}
  \label{fig:constrained-type-grammar}
\end{figure}

Based on the starting point described above, we first extend the type
system with \emph{constrained scalar types}, as shown in
Figure~\ref{fig:constrained-type-grammar}, with the changes in
boldface.

The \texttt{integer} and \texttt{float} types can be constrained to an
interval of values, by specifying, inside square brackets, an upper
and/or a lower interval bound inside which the numeric value must
fall.  If one of the bounds is omitted, the negative and
the positive infinities are used, respectively.  Thus, for instance,
\texttt{float[-2.3,0.5]} includes all floating point numbers between
-2.3 and 0.5 (both inclusive), while \texttt{int[0:]} (note the
omitted upper bound) includes all non-negative integers.

Type \texttt{string} can similarly be constrained by specifying the
minimal and the maximal string length inside the square brackets.
Construct \texttt{string[$n$]} is an abbreviation for
\texttt{string[$n$:$n$]}.  Thus, for instance, \texttt{string[0:5]} is
the type of string made up of between zero and five characters, and
\texttt{string[5]} is the same as \texttt{string[5:5]}, i.e., the type
of string consisting of exactly five characters.

Another way to constrain \texttt{integer}, \texttt{float},
\texttt{boolean} and \texttt{string} types is by enumerating the
possible values inside the curly braces (the ordering is not
important).  For integer and string types, this kind of constraining
is analogous to specifying code lists.  For instance, we can use:
\begin{lstlisting}
string { "BE", "NL", "LU" }
\end{lstlisting}
as a type for country codes of Benelux countries, and we can also use:
\begin{lstlisting}
integer { -1, 0, 1 }
\end{lstlisting}
as a type for possible number signs (negative, zero, positive).

\paragraph{Syntactical differences and semantic equality.}

There are many cases where different syntactical forms of the
constrained types relate to the same set of possible values.  For
instance, \texttt{integer\{-1,0,1\}} has the same meaning as
\texttt{integer\{1,0,-1\}} and \texttt{integer\{1,-1,0\}} etc.,
because the order in which the possible values are enumerated is not
significant.  Also, \texttt{integer[1:3]} has the same meaning as
\texttt{integer\{1,2,3\}} because the latter enumerates all integers
between 1 and 3 (both inclusive).  Similar additional examples include the
semantic equality between \texttt{string[0]} and
\texttt{string\{""\}}, and between \texttt{boolean\{true,false\}} and
\texttt{boolean} (because both possible Boolean values are enumerated).

\paragraph{Singleton types and constants.}

Constrained scalar types that allow just one value are special because
they are used by the VTL type system to compute constant values where
possible.  For instance, if we have the following assignment:
\begin{lstlisting}
Pi := 3.1415926
\end{lstlisting}
the type system will assign to \texttt{Pi} type
\texttt{float\{3.1415926\}}, which can allow it to treat \texttt{Pi}
as a  constant, and to perform some compile-time computations with
it.  For instance, if we later have:
\begin{lstlisting}
TwoPi := 2 * Pi
\end{lstlisting}
then the VTL compiler might be able to compute the value of
\texttt{TwoPi} statically (i.e., at compile time) and to assign it a
singleton type \texttt{float\{6.2831852\}}.  Using this information,
the compiler might next be able to, e.g., simplify the expression:
\begin{lstlisting}
if TwoPi>6 then "Yes" else "No"
\end{lstlisting}
into \texttt{"Yes"}, which has type \texttt{string\{"Yes"\}}.  All
this happens at compile-time and contributes to program optimization.

% One obvious way to extend the type system is by modeling scalar sire ze constraints and code lists.  Size constrains are often used to limit the range of scalar values: either integer ranges, or size length constraints.  On the other hand, code lists restrict integer or string values to a particular set of admissible values.

% Figure~\ref{fig:constrained-type-grammar} updates the syntax of \<scalar-type> to allow constraining integer and string types:
% \begin{itemize}
% \item Form \lit{int[$a$:$b$]} ($a\leq b$) denotes a sub-type of integers whose values fall between two integer literals $a$ and $b$, both inclusive.
% \item Form \lit{string[$a$:$b$]} ($a\leq b$) denotes a sub-type of strings, whose length in characters falls between two non-negative integer literals $a$ and $b$.  Form \lit{string[$b$]} is a shorthand for \lit{string[0:$b$]}.
% \item Form \lit{int \{$S$\}}, where $S$ is a comma-separated sequence of one or more integer literals, denotes a sub-type of integers whose values are in $S$.
% \item Form \lit{string \{$S$\}}, where $S$ is a comma-separated sequence of one or more string literals, denotes a sub-type of string whose values are in $S$.
% \end{itemize}

% The form \lit{string \{$S$\}} is especially useful, because it allows us to directly represent a code list, as an artefact in the VTL Information Model, with a type in the VTL type system.  This gives rise to the general idea: artefacts (i.e., objects) in the VTL information model should be (at least partly) expressible as types in the VTL type system.

% \begin{figure}[t]
% %  \centering

%   \<type-factor> ::=
%   \begin{syntdiag}
%     \begin{stack}
%       <scalar-type>
%       \\
%       <collection-type>
%       \\
%       <dataset-type>
%       \\
%       <\bfseries record-type>
%     \end{stack}
%   \end{syntdiag}

%   \<\bfseries record-type> ::=
%   \begin{syntdiag}
%     `record'
%     \begin{stack}
%       \\
%       <struct-spec>
%     \end{stack}
%   \end{syntdiag}

%   \caption{Introducing record types.}
%   \label{fig:record-type-grammar}
% \end{figure}

% \subsection{Record types}
% \label{sec:record-types}

% Our next step is to facilitate the FLWR expressions.  In the body of a FLWR expressions, the meaning of the dataset variables from the head of the FLWR expression changes: here, they no longer represent the entire datasets, but for the current matched rows from each dataset.  To account for that distinction, \<type-factor> is extended to include record types, as shown in Figure~\ref{fig:record-type-grammar}.  Record types share \<struct-spec> with their respective dataset types.

% This is an example where the type system needs to account for objects that arise from the internal structure of the language, which do not figure in the information model, and are not directly representable in it.

\begin{figure}[t]
%  \centering

  \<type> ::=
  \begin{syntdiag}
    \begin{rep}
      <type-factor>
      \\
      `\bfseries *'
    \end{rep}
  \end{syntdiag}

  \<collection-type> ::=
  \begin{syntdiag}
    \begin{stack}
      `set' \\ `list'
    \end{stack}
    `<' <\bfseries type> `>'
  \end{syntdiag}

  \caption{Introducing product types.}
  \label{fig:product-type-grammar}
\end{figure}


\subsection{Product types and universal collections}
\label{sec:product-types}

Figure~\ref{fig:product-type-grammar} introduces product types, with
changes marked in boldface.
%
Type $t_1\ast t_2\ast ... t_n$ is a Cartesian product of $n$ types
$t_1, t_2, ..., t_n$ ($n>1$).  Its elements are $n$-tuples whose
$i$-th element ($1\leq i\leq n$) belongs to $t_i$.
%
For instance, type:
\begin{lstlisting}
string[0:2] * integer[:0] * boolean
\end{lstlisting}
includes values \texttt{("LU",7,true)}, \texttt{("N",80,false)}, and
\texttt{("",4,false)}, but excludes, e.g., \texttt{("BEL",85, true)}
and \texttt{("NL",-1,false)}.

Product types are practically useful for several reasons. Firstly,
they allow natural expression of exclusion or inclusion criteria
(i.e., constraints) over values of two or more dataset components.
Secondly, products, in conjunction with collections, are the simplest
way for creating data structures (such as association lists and
histograms) which are often required by more sophisticated data
processing algorithms.

That is why in Figure~\ref{fig:product-type-grammar}
we also allow lists and sets to range over arbitrary types, not just
scalars.

% \paragraph{Complexity vs.\@ complication.}

% Extending lists and sets to arbitrary types is a design point which
% emphasizes generality of design.  It does increase complexity of the
% type system, because it now becomes possible to specify collections
% over products involving productions themselves, datasets and other
% complex types yet to be introduced in this step-by-step guide.

% However, this complexity is combinatorial in nature while based on a
% simple base mechanism.  In contrast, extending lists and sets only to
% products of scalar types would complicate the system, since it would
% require introduction of two kinds of products: a general one, and one
% restricted to scalar types only.
% %
% As a matter of principle, complexity is preferable to complication.

% ...................................................................

% \subsection{Union types}
% \label{sec:union-types}

% \begin{figure}[t]
%   \<type> ::=
%   \begin{syntdiag}
%       \begin{rep}
%         \begin{rep}
%           <type-factor>
%           \\
%           `*'
%         \end{rep}
%         \\
%         `\bfseries |'
%       \end{rep}
%   \end{syntdiag}

%   \<type-factor> ::=
%   \begin{syntdiag}
%     \begin{stack}
%       <scalar-type>
%       \\
%       <collection-type>
%       \\
%       <dataset-type>
%       \\
%       `\bfseries(' <\bfseries type> `\bfseries)'
%     \end{stack}
%   \end{syntdiag}

%   \caption{Introducing union types.}
%   \label{fig:union-type-grammar}
% \end{figure}


% Another extension which will be useful is shown in
% Figure~\ref{fig:union-type-grammar}, with additions in boldface.

% The idea behind the union types is to put several types separated by
% the pipe symbol \lit{|} as possible types for an object.  Symbol
% \lit{|} is then read as ``or.''  For instance, type:
% \begin{lstlisting}
%   number | string
% \end{lstlisting}
% is a scalar type that accepts numbers and strings, but neither dates
% nor Booleans.  Equivalently, we can say that the type:
% \begin{lstlisting}
%   integer | float
% \end{lstlisting}
% is effectively equivalent to \texttt{number}.  In fact, the union
% types are probably not so interesting for the end user, but are a
% useful internal mechanisms for expressing types such as
% \texttt{number}.  We will come back to this when we discuss type
% bounds and type \texttt{null} below.

% Another purely syntactic extension in
% Figure~\ref{fig:union-type-grammar} is in \<type-factor> to allow
% parenthesised factors.  This is important because \lit{*} binds more
% closely than \lit{|}, so that $t_1*(t_2|t_3)$ is different than
% $t_1*t_2|t_3$.  The latter is the same as $(t_1*t_2)|t_3$.

\paragraph{Smart type testing.}

VTL 1.1 includes the operator \lit{is} for run-time type checking.
For instance, expression:
\begin{lstlisting}
  l is integer
\end{lstlisting}
returns \texttt{true} if and only if the value held in \texttt{l} is
an integer.  The construct:
\begin{lstlisting}
  l is not integer
\end{lstlisting}
is just a syntactic sugar for:
\begin{lstlisting}
  not(l is integer)
\end{lstlisting}

If at compile time the type of \texttt{l} is known to be
\texttt{integer} (or any of the \texttt{integer} constraint
sub-types), then the compiler should replace \lit{l is integer} with
\lit{true}.  Conversely, if at compile time it is known that
\texttt{l} cannot be an integer (e.g., because it is known to be
\texttt{string}), the compiler should replace \lit{l is integer} with
\lit{false}.  However, the most interesting cases are those where
\texttt{l} may or may not hold an integer: in these cases, the type
testing is done at run-time.

% In addition, the compiler should be able to remember (in simple and
% unambiguous cases) when type testing is successful and when not.
% Take, for instance, the following code:
% \begin{lstlisting}
%   define function f(x as number, y as number,
%                     e as scalar := false) {
%     if e = false then
%       (x+y)/2     // Refined inference: e as boolean {false}
%     else if e = true
%       2/(1/x+1/y)
%     else
%       pow(x*y, -e)
%   }
% \end{lstlisting}
% Function \texttt{f} takes two mandatory numeric arguments, \texttt{x}
% and \texttt{y} and an optional argument \texttt{e} which can be either
% a non-negative integer or a \texttt{boolean}, with \texttt{false} as the
% default value.
% %
% If \texttt{e} is not given (or if it is explicitly specified as
% \texttt{false}), the function computes the arithmetic average of
% \texttt{x} and \texttt{y}, $(x+y)/2$.
% %
% For instance, \texttt{f(2,8)} gives \texttt{5}.
% %
% If \texttt{e} is specified as \texttt{true}, the function computes:
% \begin{displaymath}
%   \frac{2}{\frac{1}{x}+\frac{1}{y}}\,,
% \end{displaymath}
% %
% For instance, \texttt{f(2,8,e:true)} gives \texttt{3.2}.
% %
% Finally, if \texttt{e} is an integer, the the function computes
% the geometric mean of \texttt{x} and \texttt{y} to the degree
% \texttt{e}:
% \begin{displaymath}
%   \left(xy\right)^{-e} = \sqrt[e]{xy} \,.
% \end{displaymath}
% For instance, \texttt{f(2,8,e:2)} gives \texttt{4}.

% If we just write \texttt{pow(x*y, -e)} without previously checking the
% conditions using the conditional statements, the compiler will
% complain by issuing a type error, because operations such as negation
% and rising to a power are not defined for Boolean arguments, and
% \texttt{e} may be a \texttt{boolean}.
% %
% Let us now see how the tests affect the type inference in the
% definition of \texttt{f}:
% \begin{compactitem}
% \item The first \texttt{if} condition, \texttt{e=false}, refines the
%   type information of \texttt{e} after the first \texttt{then} and the
%   first \texttt{else}:
%   \begin{compactitem}
%   \item After the first \texttt{then}, the type of \texttt{e} is
%     \texttt{boolean\{false\}}, and
%   \item After the first \texttt{else}, the type of \texttt{e} is
%     \texttt{integer[0:]|boolean\{true\}}.
%   \end{compactitem}
% \item The second \texttt{if} condition, \texttt{e=true}, further
%   refines the type information for \texttt{e} after the second
%   \texttt{then} and the second \texttt{else}:
%   \begin{compactitem}
%   \item After the second then, the type of \texttt{e} is
%     \texttt{boolean\{true\}}, and
%   \item After the second else, the type of \texttt{e} is \texttt{integer[0:]}.
%   \end{compactitem}
% \end{compactitem}

% Therefore, after the second \texttt{else}, the compiler knows that
% \texttt{e} must be a non-negative integer.

% Another way to write this function (with type annotations in comments)
% would be:
% \begin{lstlisting}
%   define function f(x as number, y as number,
%                     e as integer[0:]|boolean := false) {
%     if e is integer then
%       // e is integer[0:]
%       pow(x*y, -e)
%     else
%       // e is boolean  
%       if e then
%         // e is boolean{true}
%         (x+y)/2
%       else
%         // e is boolean{false}  
%         2/(1/x+1/y)
%       else
%   }
% \end{lstlisting}

% Note that in the first \texttt{if} condition it was sufficient to test
% \texttt{e is integer} instead of the more detailed \texttt{e is
%   integer[0:]}.  We could have equally used \texttt{e is number}.

% -------------------------------------------------------------------

\subsection{Type bounds}
\label{fig:type-bounds}

\begin{figure}[]
%  \centering
  % \begin{grammar}
  %   <type> ::= <fun-type> | <prod-type>

  %   <fun-type> ::= <prod-type> `->' <type>

  %   <prod-type> ::= <type-factor> `*' <product-type> | <type-factor>

  %   <type-factor> ::= <scalar-type>
  %   \alt <collection-type>
  % \end{grammar}

  \<type-factor> ::=
  \begin{syntdiag}
    \begin{stack}
      `\bfseries any'
      \\
      <scalar-type>
      \\
      <collection-type>
      \\
      <dataset-type>
      \\
      `(' <type>
      `)'
      \\
      `\bfseries none'
      % \\
      % `\textbf(' `\textbf)'
    \end{stack}
  \end{syntdiag}

  \<scalar-type> ::=
  \begin{syntdiag}
    \begin{stack}
      `\bfseries scalar'
      \\
       `number'
      \\
      `integer'
      \begin{stack}
        \\
        `['
        \begin{stack}
          <int-literal>
          `:'
          \begin{stack}
          \\
          <int-literal>
          \end{stack}
          \\
          `:' <int-literal>
        \end{stack}
        `]'
        \\
        `{' \begin{rep} <int-literal> \\
            `,' \end{rep} `}'
      \end{stack}
      \\
      `float'
      \begin{stack}
        \\
        `['
        \begin{stack}
          <float-literal>
          `:'
          \begin{stack}
          \\
          <float-literal>
          \end{stack}
          \\
          `:' <float-literal>
        \end{stack}
        `]'
        \\
        `{' \begin{rep} <float-literal> \\
            `,' \end{rep} `}'
      \end{stack}
      \\
      `boolean'
      \begin{stack}
        \\
        `{'
          \begin{rep}
            \begin{stack}
              `true' \\ `false'
            \end{stack}
            \\
            `,'
          \end{rep}
          `}'
      \end{stack}
      \\
      `date'
      \\
      `string'
      \begin{stack}
        \\
        `[' <nat-literal>
        \begin{stack}
          \\
          `:' <nat-literal>
        \end{stack}
        `]'
        \\
        `{'
          \begin{rep}
            <string-literal>
            \\
            `,'
          \end{rep}
          `}'
      \end{stack}
    \end{stack}
  \end{syntdiag}

  \<collection-type> ::=
  \begin{syntdiag}
    \begin{stack}
      `\bfseries collection' \\ `set' \\ `list'
    \end{stack}
    `<' <type> `>'
  \end{syntdiag}

  % \<dataset-type> ::=
  % \begin{syntdiag}
  %   `dataset'
  %   \begin{stack}
  %     \\
  %     <struct-spec>
  %   \end{stack}
  % \end{syntdiag}

  % \<record-type> ::=
  % \begin{syntdiag}
  %   `record'
  %   \begin{stack}
  %     \\
  %     <struct-spec>
  %   \end{stack}
  % \end{syntdiag}

  % \<struct-spec> ::=
  % \begin{syntdiag}
  %   `{'
  %     \begin{stack}
  %       \\
  %       \begin{rep}
  %         <role> <IDENT> `as' <scalar-type> \optSemiCol
  %         \\
  %       \end{rep}
  %     \end{stack}
  %     \begin{stack}
  %       \\
  %       `...'
  %     \end{stack}
  %     `}'
  % \end{syntdiag}

  \caption{Introducing the type bounds.}
  \label{fig:lattice-type-grammar}
\end{figure}

Figure~\ref{fig:lattice-type-grammar} introduces several abstract
types that function as bounds on concrete types, with the changes set in
boldface.

Before looking into the particular extensions, let us introduce some
notions important for understanding them.  If $t$ is a type, then we
write $\denot{t}$ to denote the set of objects that belong to $t$.
Sometimes, that set is finite and clearly defined, e.g.,
$\denot{\mathtt{boolean}} = \{\mathtt{true}, \mathtt{false}\}$, or
$\denot{\mathtt{integer[1:3]}} = \{1, 2, 3\}$, but in other cases it
can be infinite or implementation dependent.  For instance, typically
we do not know what $\denot{\mathtt{integer}}$ exactly is, because the
actual repertoire of allowed integer values depends on the number of
bits used in the implementation system.  However, we are more
interested in the relationships that exists between types than in
their precise set of objects.

The basic relationship between types is \emph{subsumption}: we say
that $t_1$ is subsumed by $t_2$, and write $t_1<:t_2$, if
$\denot{t1}\subseteq \denot{t_2}$, i.e., when all objects of $t_1$ are
also objects of $t_2$.  Equivalently, we say that $t_2$ is more
general than $t_1$, that $t_2$ generalizes $t_1$, or that $t_1$
specializes $t_2$.  For instance, $\mathtt{float}<:\mathtt{number}$,
$\mathtt{integer}<:\mathtt{number}$, and
$\mathtt{integer\{2,4,6\}}<:\mathtt{integer[0:10]}$.

From the mathematical point of view, subsumption is a partial
pre-order relation on the set of all types.  It is reflexive, because
$t<:t$ for arbitrary $t$, and transitive, because from $t<:t'$ and
$t'<:t''$ it follows that $t<:t''$.  However, it is not antisymmetric,
because for instance
$\mathtt{integer[0:2]}<:\mathtt{integer\{0,1,2\}}$ and
$\mathtt{integer\{0,1,2\}}<:\mathtt{integer[0:2]}$, although
$\mathtt{integer\{0,1,2\}}$ and $\mathtt{integer[0:2]}$ are two
syntactically distinct types.

From the theoretical perspective, it is better to work directly with
$<:$ rather than with $\denot{\cdot}$, not least because, as noted
already, we may not know the actual coverage of the scalar types such
as \texttt{integer} or \texttt{float}, which may be
implementation-dependent.  In that context, we can manipulate the set
of types to achieve some useful properties.  One such property is
completeness, which for two arbitrary types $t$ and $t'$ requires the
existence of type $\tau$ such that $t<:\tau$ and $t'<:\tau$ and of
type $\tau'$ such that $\tau'<:t$ and $\tau'<:t'$; we call $\tau$ and
$\tau'$ the upper and the lower bounds of $t$ and $t'$, respectively.
We write $t\sqcup t'$ and $t'\sqcap t$ to denote the \emph{least upper
  bound}, and the \emph{greatest lower bound} of $t$ and $t'$,
respectively.

To achieve completeness, in Figure~\ref{fig:lattice-type-grammar} we
first introduce the global upper and lower bound types:
\begin{itemize}
\item Type \texttt{any} is the global upper bound of the whole type
  system, and covers all possible objects.  In other words, any other
  type is a (strict) subtype of \texttt{any}.  Type \texttt{any} is
  useful because, being the most general type, it carries least
  information about any particular object.  Therefore, when the
  programmer specifies type \texttt{any} (or the compiler infers it),
  this means that there is no ground for making any assumption about
  the object.

\item Type \texttt{none} is the global lower bound to the whole type
  system, the antithesis of \texttt{any}, with
  $\denot{\texttt{none}}=\emptyset$.  It generally corresponds
  to \texttt{void} in Java and C/C++.  Assigning type \texttt{none} to
  an object is the same as saying that it does not exist.
\end{itemize}

Aside of the global upper and lower bounds, we also introduce the
following upper bound types for scalars and collections:
\begin{itemize}
\item Type \texttt{scalar} is the upper bound for all scalar types.
  If an object has type \texttt{scalar}, it must be either a
  \texttt{number}, a \texttt{boolean}, a \texttt{date} or a
  \texttt{string}, or \texttt{null} (discussed below).
  %
  % In fact, \texttt{scalar} behaves exactly as if it was defined with
  % (syntactically incorrect):
  % \begin{lstlisting}
  %   type scalar = number | boolean | date | string | null
  % \end{lstlisting}

\item For arbitrary type $t$, type \texttt{collection<$t$>} is the
  upper bound for both \texttt{list<$t$>} and \texttt{set<$t$>}.
  % , and
  % behaves exactly as if it was defined with (syntactically incorrect):
  % \begin{lstlisting}
  %   type collection<T> = list<T> | set<T>
  % \end{lstlisting}
  % for any given \texttt{T}.
\end{itemize}

% ......................................................................

\subsection{Null type and nullable types}
\label{sec:null-type}

\begin{figure}[]

  \<type> ::=
  \begin{syntdiag}
    \begin{rep}     
      \begin{stack}
        `\bfseries null'
        \\
        <type-factor>
        \begin{stack}
          \\
          `\bfseries ?'
        \end{stack}
      \end{stack}
      \\
      `*'
    \end{rep}
  \end{syntdiag}

  \<type-factor> ::=
  \begin{syntdiag}
    \begin{stack}
      <scalar-type>
      \\
      <collection-type>
      \\
      <dataset-type>
      \\
      `\bfseries(' <\bfseries type> `\bfseries)'
    \end{stack}
  \end{syntdiag}

  \caption{Introducing type \texttt{null} and nullable types.}
  \label{fig:null-type-grammar}
\end{figure}

Figure \ref{fig:null-type-grammar} introduces a new type
\texttt{null}.  This is a special type that has exactly one value,
also called \texttt{null}.  Value \texttt{null} is a distinct marker
that represents a missing or unknown value from any other type.

The main motivation for introducing type \texttt{null} is to model the
possibility of missing or unknown data in dataset measures and
attributes.  This is implicit in dataset structure definitions, both
in dataset types and in the actual structures of dataset instances.

We also extend the syntax for \<type> to allow any \<type-factor> to
be followed with a question mark \lit{?}.  This means that the type is
\emph{nullable}, i.e., it may include the \texttt{null} value.
Nullability is implicitly used in type definitions for measures and
attributes in dataset types.  If a measure or attribute is declared
with type $t$ (say \texttt{number} or \texttt{string}), then the
effective type is \texttt{$t$?} (say \texttt{number?} or
\texttt{string?}).
%
Of course, the implicit nullability does not apply to identifier
components, which by definition cannot have value \texttt{null}.

All arithmetic and logical operations accept nullable inputs and
produce nullable outputs.  For instance, numeric addition takes two
arguments of type \texttt{number?} and produces a result of type
\texttt{number?}.  This covers also the case where one or both of
arguments are known to be non-nullable, for instance because they come
from a literal written in the program or from an identifier
component. The type inference algorithm should detect the case when
all inputs to a scalar operation such as plus are non-nullable, and to
flag the result as non-nullable.

For instance, expression
\begin{lstlisting}
1 + x 
\end{lstlisting}
where \texttt{x} stands for a numeric measure or attribute component
(type \texttt{number?}) has inferred type \texttt{number?}, because
the result is \texttt{null} if \texttt{x} is \texttt{null}.
%
However, the same expression where \texttt{x} stands for an identifier
component has the inferred type \texttt{number}, where \texttt{null}
values are excluded.

In Figre~\ref{fig:null-type-grammar} we also include parenthesised
types in \<type-factor>, in order to be able to express, for instance,
\texttt{($t_1$ * $t_2$)?} as opposed to \texttt{$t_1$ * $t_2$?}.  The
latter is the same as \texttt{$t_1$ * ($t_2$?)}.  Using parenthesis is
also useful in the syntax of function types, which we introduce next.

\paragraph{More precise type inference.}

A good type inference algorithm should be able to use the type
information and type tests with the lit{is} operator to infer more
precise types for different values computed in a VTL program.

As an example, let us take the following function which takes an
optional named argument \texttt{y} of type \lit{number?} with default
value \texttt{null}:
\begin{lstlisting}
define function f(x as number, y as number? := null) as number {
  if y is null then
    // Refined typing: x is null
    1/x
  else
    // Refined typing: x is number (not nullable)
    (y-x)/(y+x)
}
\end{lstlisting}

A call like \texttt{f(5)} would be the same as \texttt{f(5, y: null)}
and would evaluate to $1/5 = 0.2$.  But a call like \texttt{f(5, 1)}
would evaluate to $-4/6=-0.666666$.

Note that this function promises to return \texttt{number} which is
not nullable.  If the test \lit{y is null} succeeds, the compiler
knows that the actual type of \texttt{y} is \texttt{null}, and
computes \texttt{1/x}, which is all right because \texttt{x} cannot be
\texttt{null} and the result of \texttt{1/x} must be a non-nullable
number.  If the test fails, however, the compiler should be able to
update its type inference for \texttt{x} from \texttt{number?} to
\texttt{number}, and since both \texttt{x} and \texttt{y} are of type
\texttt{number}, the result of \texttt{(1-x)/(1+x)} is also number.
Without the test, however, the type of \texttt{(1-x)/(1+x)} would be
\lit{number?}, and therefore incompatible with the promised return
type \texttt{number}.

% ----------------------------------------------------------------------

\subsection{Function types}
\label{sec:function-types}

\begin{figure}[bt]
  \<type> ::=
  \begin{syntdiag}
    \begin{rep}
      % \begin{rep}
        \begin{rep}
          \begin{stack}
            `null' \\
            <type-factor>
            \begin{stack}
              \\
              `?'
            \end{stack}
          \end{stack}
            \\
            `*'
        \end{rep}
      %   \\
      %   `|'
      % \end{rep}
      \\
      `\bfseries ->'
    \end{rep}
  \end{syntdiag}
  
  \caption{Introducing function types.}
  \label{fig:function-type-grammar}
\end{figure}


Figure~\ref{fig:function-type-grammar} changes the definition of
\<type> to allow writing of function types of the form
\lit{$t$->$t'$}, where $t$ and $t'$ are arbitrary types.  In the text
we will often write $t\to t'$ for the same thing.

\paragraph{Co-variance and contra-variance.}

In $t\to t'$, types $t$ and $t'$ behave differently with
respect to the type subsumption relation $<:$.
%
Take, for instance, types \texttt{list<$t$>} and \texttt{list<$t'$>}.
For the subsumption \texttt{list<$t$>\,$<:$\,list<$t'$>} to hold, it is
necessary and sufficient that $t<:t'$.  This intuitively makes sense:
a list of integers is a list of numbers, because integers are numbers.
Or, in other words, where a list of numbers is expected, we can supply
a list of integers.  Since $t$ behaves in the same way with respect to
$<:$ as \texttt{list<$t$>}, we say that the type parameter of
\texttt{list} is \emph{co-variant}.

Let us now suppose ask for a function of type $t\to t'$, and are
offered a function $f$ of type $\tau\to\tau'$.  Under which
circumstances can we accept the offer?  In other words, when is
$\tau\to\tau'<:t\to t'$?
\begin{compactitem}
\item Firstly, $f$ must be able to accept any value from $t$, but it
  does not hurt if it accepts a wider class of objects.  In other
  words, we require that $t<:\tau$.
 
\item Secondly, $f$ must not surprise us by returning something
  outside $t'$, but it is okay if it restricts its return values to a
  subset of $t'$.  In other words, we require that $\tau'<:t'$.
\end{compactitem}

To summarize, $\tau\to\tau'<:t\to t'$ if and only if $t<:\tau$ and
$\tau'<:t'$.  We say that $t'$ is co-variant while $t$ is
\emph{contra-variant} in $t\to t'$.

% One particular application of contra-variance is in functions that do
% not accept any arguments.  Suppose we have a function \texttt{f} of
% type \texttt{none -> integer}.  We call it with \texttt{f()}



% ...................................................................

\subsection{Named type definitions}
\label{sec:named-type-def}

\begin{figure}[t]
%  \centering
  % \begin{grammar}
  %   <type> ::= <fun-type> | <prod-type>

  %   <fun-type> ::= <prod-type> `->' <type>

  %   <prod-type> ::= <type-factor> `*' <product-type> | <type-factor>

  %   <type-factor> ::= <scalar-type>
  %   \alt <collection-type>
  % \end{grammar}

  % \<type> ::=
  % \begin{syntdiag}
  %   \begin{rep}
  %       \begin{rep}
  %         <type-factor>
  %         \\
  %         `*'
  %       \end{rep}
  %     \\
  %     `\bfseries ->'
  %   \end{rep}
  % \end{syntdiag}

  \<\bfseries type-def> ::=
  \begin{syntdiag}
    `type' <IDENT> `=' <type> \optSemiCol
  \end{syntdiag}

  \<scalar-type> ::=
  \begin{syntdiag}
    \begin{stack}
      `scalar'
      \\
      `number'
      \\
      `integer'
      \begin{stack}
        \\
        `['
        \begin{stack}
          <int-literal>
          `:'
          \begin{stack}
          \\
          <int-literal>
          \end{stack}
          \\
          `:' <int-literal>
        \end{stack}
        `]'
        \\
        `{' \begin{rep} <int-literal> \\
            `,' \end{rep} `}'
      \end{stack}
      \\
      `float'
      \begin{stack}
        \\
        `['
        \begin{stack}
          <float-literal>
          `:'
          \begin{stack}
          \\
          <float-literal>
          \end{stack}
          \\
          `:' <float-literal>
        \end{stack}
        `]'
        \\
        `{' \begin{rep} <float-literal> \\
            `,' \end{rep} `}'
      \end{stack}
      \\
      `boolean'
      \begin{stack}
        \\
        `{'
          \begin{rep}
            \begin{stack}
              `true' \\ `false'
            \end{stack}
            \\
            `,'
          \end{rep}
          `}'
      \end{stack}
      \\
      `date'
      \\
      `string'
      \begin{stack}
        \\
        `[' <nat-literal>
        \begin{stack}
          \\
          `:' <nat-literal>
        \end{stack}
        `]'
        \\
        `{'
          \begin{rep}
            <string-literal>
            \\
            `,'
          \end{rep}
          `}'
      \end{stack}
      \\
      <\bfseries qname>
    \end{stack}
  \end{syntdiag}

  \<\bfseries qname> ::=
  \begin{syntdiag}
    % \begin{stack}
    %   \\
    %   `::'
    % \end{stack}
    \begin{rep}
	  <IDENT>
      \\
      `::'
    \end{rep}
  \end{syntdiag}

  % \<dataset-type> ::=
  % \begin{syntdiag}
  %   `dataset'
  %   \begin{stack}
  %     \\
  %     <struct-spec>
  %   \end{stack}
  % \end{syntdiag}

  % \<record-type> ::=
  % \begin{syntdiag}
  %   `record'
  %   \begin{stack}
  %     \\
  %     <struct-spec>
  %   \end{stack}
  % \end{syntdiag}

  % \<struct-spec> ::=
  % \begin{syntdiag}
  %   `{'
  %     \begin{stack}
  %       \\
  %       \begin{rep}
  %         <role> <IDENT> `as' <scalar-type> \optSemiCol
  %         \\
  %       \end{rep}
  %     \end{stack}
  %     \begin{stack}
  %       \\
  %       `...'
  %     \end{stack}
  %     `}'
  % \end{syntdiag}

  \caption{Introducing named type definitions.}
  \label{fig:named-type-grammar}
\end{figure}

So far, we have assumed that all types are directly written in the
presented syntax.  However, the good practice indicates that it would
be very useful to be able to define types and refer to them by name.
Figure~\ref{fig:named-type-grammar} presents new rule \<type-def>
which allows giving names to type definitions.  For example, we can
define the following code list type:
\begin{lstlisting}
type EU12_CL = string { "BE", "DE", "DK", "ES", "FR", "GR",
                        "IE", "IT", "LU", "NL", "PT", "UK" }
\end{lstlisting}
and refer to it later on by name \lit{EU12\_CL}.

Syntax rule \<scalar-type> is extended to include the possibility of
referring to a type by a qualified name, or \<qname>.
%
This may at first look a bit odd, since type definitions do not need
to be restricted to scalar types only.  However, we would like to be
able to use named type references in \texttt{dataset} structure
definitions, which syntactially require a \<scalar-type>.  In such
situations, the compiler has to check whether the type definition
really defines a scalar type or not.

References to a named type are done using \<qname>, which is either s
single identifier, or two or more identifiers separated by \lit{::}.
The latter form is used to refer to module members.

% If \<qname>
% starts with \lit{::}, the identifiers that follow belong to the global
% namespace.

% Named type definitions take their place in the type hierarchy
% according to the definition on the right side of \lit{=}.  This means
% that two differently named types are equivalent exactly when their definitions
% are equivalent.

% ...................................................................

\subsection{Information model artefacts as named types}
\label{sec:inform-model-artef}

A number of VTL data definition statements define persistent objects
that can be naturally seen as types.  These include:
\begin{compactitem}
\item value domains,
\item value domain subsets, and
\item dataset structures.
\end{compactitem}

The names defined using these data definition statements can be
automatically used as named types, and will be interpreted
accordingly:
\begin{compactitem}
\item Names of persistent value domains and value domain subsets are
  interpreted names of user-defined (constrained) scalar types.
\item Names of persistent data structures are interpreted as fully
  specified dataset types.
\end{compactitem}

% ...................................................................

% \subsection{Types for types}
% \label{sec:types-types}

% \begin{figure}[t]
% %  \centering
%   % \begin{grammar}
%   %   <type> ::= <fun-type> | <prod-type>

%   %   <fun-type> ::= <prod-type> `->' <type>
%   %   <prod-type> ::= <type-factor> `*' <product-type> | <type-factor>

%   %   <type-factor> ::= <scalar-type>
%   %   \alt <collection-type>
%   % \end{grammar}

%   % \<type> ::=
%   % \begin{syntdiag}
%   %   \begin{rep}
%   %       \begin{rep}
%   %         <type-factor>
%   %         \\
%   %         `*'
%   %       \end{rep}
%   %     \\
%   %     `\bfseries ->'
%   %   \end{rep}
%   % \end{syntdiag}

%   \<type-factor> ::=
%   \begin{syntdiag}
%     \begin{stack}
%       `any'
%       \\
%       <scalar-type>
%       \\
%       <collection-type>
%       \\
%       <dataset-type>
%       \\
%       <record-type>
%       \\
%       <qname>
%       \\
%       `\bfseries type' `\bfseries<' <\bfseries type> `\bfseries,'
%        <\bfseries type> `\bfseries>'
%       \\
%       `(' <type> `)'
%       \\
%       `(' `)'
%     \end{stack}
%   \end{syntdiag}

%   \caption{Introducing types for types.}
%   \label{fig:type-type-grammar}
% \end{figure}

% As mentioned in the introduction, the defined types are reified, which
% is to say that they have their object representation.  Objects that
% represent types also need to have their own type, introduced in
% Figure~\ref{fig:type-type-grammar}.
% %
% In the previous example of the named type definition \lit{EU12_CL},
% an object is created and named \lit{EU12_CL}, whose type is
% \lit{type<$t$>}, where $t$ refers to the right side of \lit{=}.
% Obviously, the most general type for a type is \lit{type<any>}.

% ...................................................................

\subsection{Module types}
\label{sec:module-types}

\begin{figure}[t]

%  \centering
  % \begin{grammar}
  %   <type> ::= <fun-type> | <prod-type>

  %   <fun-type> ::= <prod-type> `->' <type>
  %   <prod-type> ::= <type-factor> `*' <product-type> | <type-factor>

  %   <type-factor> ::= <scalar-type>
  %   \alt <collection-type>
  % \end{grammar}

  % \<type> ::=
  % \begin{syntdiag}
  %   \begin{rep}
  %       \begin{rep}
  %         <type-factor>
  %         \\
  %         `*'
  %       \end{rep}
  %     \\
  %     `\bfseries ->'
  %   \end{rep}
  % \end{syntdiag}

  \<type-factor> ::=
  \begin{syntdiag}
    \begin{stack}
      `any'
      \\
      <scalar-type>
      \\
      <collection-type>
      \\
      <dataset-type>
      \\
      <\bfseries module-type>
      \\
      `(' <type> `)'
      \\
      `none'
      % \\
      % `\textbf(' `\textbf)'
    \end{stack}
  \end{syntdiag}


  \<\bfseries module-type> ::=
  \begin{syntdiag}
      `module'
      \begin{stack}
        \\
        \begin{stack}
          <signature>
          \\
          `type' <qname>
          \\
          `(' <type> `)'
        \end{stack}
      \begin{stack}
        \\
        \begin{rep}
          `with'
          \begin{stack}
            <signature>
            \\
            <qname>
            \\
            `module' `(' <type> `)'
          \end{stack}
          \\
        \end{rep}
      \end{stack}
      \end{stack}
  \end{syntdiag}

  \<\bfseries signature> ::=
  \begin{syntdiag}
    `{'
      \begin{stack}
        \\
        \begin{rep}
          <import> \optSemiCol
          \\
        \end{rep}
      \end{stack}
      \begin{stack}
        \\
        \begin{rep}
         \begin{stack}
            <IDENT> `as' <type>
            \\
            `type' <IDENT>
            \begin{stack} `=' \\ `<:' \end{stack}
            <type>
          \end{stack}
          \optSemiCol
          \\
        \end{rep}
      \end{stack}
    `}'
  \end{syntdiag}

  \<\bfseries import> ::=
  \begin{syntdiag}
    `import'
    <qname>
    \begin{stack}
      \\
      `as' <IDENT>
      \\
      `::'
      \begin{stack}
        <IDENT>
        \\
        `*'
        \\
        `{'
          \begin{rep}
            <IDENT>
            \begin{stack}
              \\
              `as' <IDENT>
            \end{stack}
            \\
            `,'
          \end{rep}
          `}'
      \end{stack}
    \end{stack}
  \end{syntdiag}

  % \<\bfseries restriction> ::=
  % \begin{syntdiag}
  %   `(' \begin{rep} <IDENT> \\ `,' \end{rep} `)'
  % \end{syntdiag}

  % \<dataset-type> ::=
  % \begin{syntdiag}
  %   `dataset'
  %   \begin{stack}
  %     \\
  %     <struct-spec>
  %   \end{stack}
  % \end{syntdiag}

  % \<record-type> ::=
  % \begin{syntdiag}
  %   `record'
  %   \begin{stack}
  %     \\
  %     <struct-spec>
  %   \end{stack}
  % \end{syntdiag}

  % \<struct-spec> ::=
  % \begin{syntdiag}
  %   `{'
  %     \begin{stack}
  %       \\
  %       \begin{rep}
  %         <role> <IDENT> `as' <scalar-type> \optSemiCol
  %         \\
  %       \end{rep}
  %     \end{stack}
  %     \begin{stack}
  %       \\
  %       `...'
  %     \end{stack}
  %     `}'
  % \end{syntdiag}

  \caption{Introducing module types.}
  \label{fig:module-type-grammar}
\end{figure}

At this point we come to the biggest and most important extension of
the type system: the introduction of module types, as shown in
Figure~\ref{fig:module-type-grammar}, with changes to \<type-factor>
given in boldface.  Before going into details, we first clarify to
what kind of objects module types refer.

A module packages together a set of named objects and user-defined
types.  A name that refers to an object inside the module is called an
\emph{object member}, while a name that refers to a (user-defined)
type inside the module is called a \emph{type member}.  The set of
members with their types is called the \emph{module signature}.  The
module signature is in fact the public interface that the module
exposes to the outside world.  In the nutshell, the module types
define module signatures.  For instance:
\begin{lstlisting}
type Country = module {
  name as string
  continent as string
}
\end{lstlisting}
defines a module type named \texttt{Country}, whose signature consists
of two object members, \texttt{name} and \texttt{continent}, both of
type \texttt{string}.

A module type is \emph{instantiated} by specifying the values of all
object members from its signature, plus specifying the exact type for
all type members for which the signature specifies only the upper
bounds. For instance:
\begin{lstlisting}
  hr := new Country {
    name := "Croatia"
    continent := "Europe"
  }
\end{lstlisting}
creates a new module instance of \texttt{Country} and stores it in
\texttt{hr}.  We can access its module members using their qualified
names, \texttt{hr::name} and \texttt{hr::continent}.

Alternatively, modules can be created \emph{ad-hoc}, i.e.,
without referring to a module type, but just defining object and type
members at will.  For example, we could have also written:
\begin{lstlisting}
  hr := new module {
    name := "Croatia"
    continent := "Europe"
  }
\end{lstlisting}
(without specifying \texttt{Country} after \texttt{new}), and the
result would be the same.  However, the advantage of using
\texttt{Country} is that the compiler can check that all object
members are initialised with the correct types.
%
The compiler infers the signature of the ad-hoc module automatically
from the definition of its members.

Once a module is created, its members are \emph{immutable}, which is
to say that one cannot change the object and type members inside an
object.  Immutability is a very important property of modules, which
simplifies type analysis and eliminates many potential programming
errors.

The first and most natural association would be to relate module types
with VTL modules, which are reusable units of code which can be
developed separately and then combined into (or used from) a VTL
program.  This is a correct association, and indeed the module types
we are presenting here are used to support this kind of modules.

However, the notion of module is much more granular than these ``big''
modules.  In essence, a module is any (immutable) object that exposes
a well-defined interface to the outside world.  Therefore, modules can
be small and big, dynamically created or written in separate VTL
source files and automatically compiled and loaded by the VTL system
and runtime.  Besides, various types of rule sets, information model
artefacts, etc., are also implemented using modules.
%
The module types have been designed to support all these different
uses, with the emphasis on simplicity and clarity.

\subsubsection*{Simple module types and signatures}

\begin{figure}[tb]
\begin{syntdiag}
    `new'
    \begin{stack}
      `module'
      \\
      <qname>
    \end{stack}
    \begin{stack}
      \\
      `{'
        \begin{stack}
          \\
          \begin{rep}
            <import> \optSemiCol
            \\
          \end{rep}
        \end{stack}
        \begin{rep}
        \begin{stack}
          <IDENT> `:=' <expr>
          \\
          `type' <IDENT> `=' <type>
          % \\
          % `use' `module' <qname>
          % \begin{stack}
          %   \\
          %   `{' \begin{rep} <IDENT> \\ `,' \end{rep} `}'
          % \end{stack}
        \end{stack}
        \optSemiCol
        \\
      \end{rep}
      `}'
    \end{stack}
  \end{syntdiag}
    \caption{Module creation expression syntax.}
  \label{fig:new-expr-grammar}
\end{figure}

The simplest module type form is %:
just \lit{module}
% \begin{syntdiag}
% `module'
% \end{syntdiag}
and it refers to any kind of module.

More often, we use the module types to describe the interface that the
instances need to expose.
% The simplest form for doing this is:
% \begin{syntdiag}
% `module' `{'
% \begin{rep}
%   <IDENT> `as' <type> \optSemiCol
%   \\
% \end{rep}
% `}'
% \end{syntdiag}
% which allows us to specify one or more named module interface
% components and their types.
Going back to our earlier example, we can
define:
\begin{lstlisting}
type Country = module {
  name as string
  continent as string
}
\end{lstlisting}
We can then create an instance of this module type using the
expression syntax shown in Figure~\ref{fig:new-expr-grammar}:
\begin{lstlisting}
hr := new Country {
  name := "Croatia"
  continent := "Europe"
}
\end{lstlisting}

We can access members of the module \texttt{hr} using qualified names,
as \texttt{hr::name} and \texttt{hr::continent}.

\subsubsection*{Ad-hoc modules}

One can create a module without refering to a previously defined
module type, using \texttt{new module} syntax, e.g.:
\begin{lstlisting}
book := new module {
  title := "Hitchhiker's Guide to the Galaxy"
  author := "Douglas Adams"
  year := 1995
  reprint := true
}
\end{lstlisting}

In this case, the type of \texttt{book} will be inferred by the
compiler as:
\begin{lstlisting}
module {
  title as string { "Hitchhiker's Guide to the Galaxy" }
  author as string { "Douglas Adams" }
  year as integer { 1995 }
  reprint as boolean { true }
}
\end{lstlisting}

It should be noted that only the members 

\subsubsection*{Type members in module signatures}

Module signatures can also have type members.  Let us for instance
take a (simplified hypotetical) example of a module type that
encapsulates the information about a dataset component:
\begin{lstlisting}
type RoleName = string { "identifier", "measure", "attribute" }

type Component = module {
  name as string
  role as RoleName
  type valueType <: scalar
}
\end{lstlisting}

In this example, we have not defined exactly what the type member
\texttt{valueType} is, but have rather used \texttt{<:} to specify
that in any specific module instance it has to be a sub-type of
\texttt{scalar}.

For instance, we can create an instance:
\begin{lstlisting}
refArea := new Component {
  name := "ref_area"
  role := "identifier"
  type valueType = string[2]
}
\end{lstlisting}

Note that if we tried to write e.g. \texttt{role := "dimension"}, this
would be caught by the type system as a type error.  We can use
\texttt{refArea::valueType} wherever a named type is allowed, and it
will be interpreted as \texttt{string[2]}.

For instance, we can imagine a function defined as:
\begin{lstlisting}
define function isLegalValue(v as scalar, c as Component) as boolean {
  v is c::valueType
}
\end{lstlisting}

Now the test \texttt{isLegalValue(105, refArea)} returns
\texttt{false}, while \texttt{isLegalValue("UK", refArea)} returns
\texttt{true}.

\subsubsection*{Extending module type signatures}

It is often useful to derive new module types by adding new or
specializing the existing module type members.  For instance, based on
our example with module type \texttt{Component}, we can define:
\begin{lstlisting}
type Identifier = module type Component with {
  role as string { "identifier" }
}
type Measure = module type Component with {
  role as string { "measure" }
}
type Attribute = module type Component with {
  role as string { "attribute" }
}
\end{lstlisting}

Note that in these three definitions the type for the member
\texttt{role} specializes the original \texttt{RoleName}.  If we try
something like:
\begin{lstlisting}
type Dimension = module type Component with {
  role as string { "dimension" }
}
\end{lstlisting}
the compiler will detect that the new type for \texttt{role} is
incompatible with \texttt{RoleName}, because \texttt{"dimension"} does
not appear in in the enumeration \texttt{\{"identifier", "measure",
  "attribute"\}} and will raise a type error.

To create an instance, we can then write:
\begin{lstlisting}
refArea := new Identifier {
  name := "ref_area"
  type valueType = string[2]
}
\end{lstlisting}
without the need to set \texttt{role} to \texttt{"identifier"}
explicitly.  That is because the type for \texttt{role} in
\texttt{Identifier} is now a singleton type consisting only of string
literal \texttt{"identifier"}, and the compiler automatically assigns
that value.

\subsubsection*{Defining functions and other objects in modules}

Going back to our \texttt{Country} example, we can derive a module
type for EU Member States like this:
\begin{lstlisting}
type MemberState = module type Country with {
  memberOfEU as integer -> boolean
}
\end{lstlisting}

Here, \texttt{memberOfEU} is expected to be a function which takes an
integer (denoting a year) and returns \texttt{true} if and only if the
country has been a member of EU that year.  We can implement that
function using the normal \texttt{define function} construct:
\begin{lstlisting}
hr := new MemberState {
  name := "Croatia"
  continent := "Europe"
  define function memberOfEU(year as integer) as boolean {
    year >= 2013
  }
}
\end{lstlisting}
Which is, in this simple case, equivalent to:
\begin{lstlisting}
hr := new MemberState {
  name := "Croatia"
  continent := "Europe"
  memberOfEu := _ >= 2013
}
\end{lstlisting}
because \texttt{\_ >= 2013} is an anonymous function that takes one
numeric argument.

However, using \texttt{define function} is instructive as an example
of other statements that define and name objects, such as datasets,
rulesets, etc.  Each of these definition statements creates and names
an object in the current module scope.


% \subsubsection*{Module type inference}

% Of course, the type inference works also in the opposite direction.  If we write:
% \begin{lstlisting}
% hrStatus := module {
%   name := "Croatia"
%   memberOfEU := _ >= 2013
%   continent := "Europe"
% }
% \end{lstlisting}
% the compiler will infer that the type of \lit{hrStatus} is:
% \begin{lstlisting}
% module {
%   name as string
%   memberOfEU as int -> bool
%   continent as string
% }
% \end{lstlisting}

% And if we write:
% \begin{lstlisting}
% hrStatus := module {
%   name := "Croatia"
%   memberOfEU := _ >= 2013
%   continent := "Europe" as CONT_CL
% }
% \end{lstlisting}
% the compiler will infer that the type of \lit{hrStatus} is:
% \begin{lstlisting}
% module {
%   name as string
%   memberOfEU as int -> bool
%   continent as CONT_CL
% }
% \end{lstlisting}
% which is equivalent to \lit{CountryStatus}.

\subsubsection*{Adding more instance members}

It is allowed to add more members than required when instantiating a
module, for instance:
\begin{lstlisting}
lu := new MemberState {
  name := "Luxembourg"
  continent := "Europe"
  define function memberOfEU(year as integer) as boolean {
    year >= 1958
  }
  callingCode := "+352"
  region := "Benelux"
}
\end{lstlisting}
and no problem will arise because we have two extra members,
\lit{callingCode} and \lit{region}.  But, if we pass \lit{lu} to
a function that expects an instance of \lit{MemberState}, the two
new members will be invisible to that function.


\subsubsection*{Importing from other module instance}

In module types and module creation expressions alike, signatures
(enclosed between \lit{\{} and \lit{\}}) may include \<import>
elements.  Their role is to simplify how we refer to members in other
modules.  Imagine that module \lit{System} has member module
instance \lit{IM} (for the information model), which in turn has
member type \lit{Dataset}.  To use the latter in another module, one
should normally write \lit{System::IM::Dataset}, but, like in Java, we
can write:
\begin{lstlisting}
import System::IM::Dataset
\end{lstlisting}
after which we can (in the scope of the import) refer to it simply by
writing \lit{Dataset}.  We can also rename the imported member within
the scope of the import (e.g., to avoid name clashes) in this way:
\begin{lstlisting}
import System::IM::Dataset as SysDataset
\end{lstlisting}

To import several names in the same import statement, we can write:
\begin{lstlisting}
import System::IM::{Dataset, Component}
\end{lstlisting}
which supports the same renaming facility:
\begin{lstlisting}
import System::IM::{Dataset as SysDataset, Component as SysComponent}
\end{lstlisting}

Finally, to import all members from module \lit{System::IM}, we can write:
\begin{lstlisting}
import System::IM::*
\end{lstlisting}

Importing does not add members to a module type or a module instance.
It just makes the imported members from other modules visible in the
current namespace in the scope of the import for easier reference.

% ...................................................................

\subsection{Module view of complex types}
\label{sec:module-view-complex}

Some complex types, such as collections and datasets, can be viewed as
a module, and then become equipped with special, built-in signatures.
For example, if \texttt{T} is the element type, then \texttt{list<T>}
can be viewed as a module using the syntax:
\begin{lstlisting}
  module(list<T>)
\end{lstlisting}
which is internally expanded into the following built-in signature:
\begin{lstlisting}
  module {
    type Element = T
    size as integer[0:]
    isEmpty as boolean
    head as none -> T?
    tail as none -> module(list<T>)?
  }
\end{lstlisting}

If \texttt{l} is a variable of type \texttt{list<T>}, then we can use
the syntax \texttt{l::\emph{xyz}} to access the member
\texttt{\emph{xyz}} of \texttt{l} viewed as a module of type
\texttt{module(list<T>)}.  We can now use the following members:
\begin{itemize}
\item \texttt{l::Element} is equal to \texttt{T};
\item \texttt{l::size} is a non-negative integer giving the length of
  the list;
\item \texttt{l::isEmpty} returns \texttt{true} exactly if the list
  is empty;
\item \texttt{l::head()} gets a heading (i.e., the first) element of
  the list, or \texttt{null} if the list is empty;
\item \texttt{l::tail()} gets the tail (i.e., all elements but the
  first) of the list, or \texttt{null} if the list is empty;
\end{itemize}

For datasets types, the module view provides a modularized
representation of the dataset structure as defined by the information
model (see Section~\ref{sec:module-system-vtl}).

In general, \emph{all types} have a module view, even if in the
simplest case the signature is empty and the modules do not expose any
members.

% ...................................................................

\section{Type system and the VTL IM}
\label{sec:module-system-vtl}

To illustrate the type system's support for modeling of the IM
artefacts, we are going to look at the example of a dataset.  Let us
take the following VTL DDL statement:%
\footnote{The \texttt{define dataset} statement shown in this example
  follows a slightly modified syntax that is more in line with the
  rest of the expression and type syntax.}
\begin{lstlisting}
  define dataset population {
    description: "The population dataset"
    collected: true
    identifier ref_area as string[2]
    identifier year as integer
    identifier sex as string { "M", "F" }
    identifier age as integer[0:]
    measure obs_value as integer[0:]
    attribute obs_status as string
  }
\end{lstlisting}

This defines a named dataset stored in a persistent store with the
given name, description, properties and structure.  The effect of this
statement is not the actual creation of such a dataset in the
database.  It is assumed that such a dataset already exists, and is
materialised using some adequate technology (e.g., as an SQL table).
What \texttt{define dataset} statement does is to make this external
persistent dataset visible to VTL programs, so that they can refer to
it by name.

\subsection{IM metamodel types}

The result of the \texttt{define dataset} is the creation of a
persistent dataset object and its assignment to name \lit{population}.
Module \texttt{System::MetaModel} defines a number of types that
describe different kinds of IM objects.  For us, the relevant ones
are:
\begin{lstlisting}
  // Describes a persistent dataset
  type PersistentDataset = module {
    name as string
    description as string?
    collected as boolean
    struct as DataStructure
    type t = structure::t // Mirror the structure dataset type
  }

  // Describes a persistent data structure 
  type DataStructure = module {
    type t <: dataset // Dataset type corresponding to this structure
    name as string
    description as string?
    components as list<Component>
  }

  // Describes valid component role names
  type RoleName = string { "identifier", "measure", "attribute" }

  // Describes a component
  type Component = module {
    name as string
    role as RoleName
    type valueType <: scalar
    nullable as boolean
  }

  // Extension: identifier component
  type Identifier = module type Component with {
    role as string { "identifier" }
    nullable as boolean { false }
  }

  // Extension: measure component
  type Measure = module type Component with {
    role as string { "measure" }
    nullable as boolean { true }
  }

  // Extension: attribute component
  type Attribute = module type Component with {
    role as string { "attribute" }
    nullable as boolean { true }
  }
\end{lstlisting}

\subsection{Creating an IM instance with artefacts}

An information model is a collection of artefacts for a particular
use-case scenario.  The easiest thing is to define it in a module, for
instance:
\begin{lstlisting}
  module PopulationInfoModel

  // ...

  define dataset population {
    description: "The population dataset"
    collected: true
    identifier ref_area as string[2]
    identifier year as integer
    identifier sex as string { "M", "F" }
    identifier age as integer[0:]
    measure obs_value as integer[0:]
    attribute obs_status as string
  }

  // ...
 
\end{lstlisting}

This is equivalent, under the hood, to the following:

\begin{lstlisting}
  module PopulationInfoModel

  import System::MetaModel::*

  // ...

  data_structure_of_population := new DataStructure {
    type t = dataset {
      identifier ref_area as string[2]
      identifier year as integer
      identifier sex as string { "M", "F" }
      identifier age as integer[0:150]
      measure obs_value as integer[0:]
      attribute obs_status as string
    }
    name := "data_structure_of_population"
    components := list(
      new Identifier {
        name := "ref_area"
        type valueType = string[2]
      },
      new Identifier {
        name := "year"
        type valueType = integer
      },
      new Identifier {
        name := "sex"
        type valueType = string { "M", "F" }
      },
      new Identifier {
        name := "age"
        type valueType = integer[0:]
      },
      new Measure {
        name := "obs_value"
        type valueType = integer[0:]
      },
      new Attribute {
        name := "obs_status"
        type valueType = string
      }
    ) 
  }
  
  population := new PersistentDataset {
    name := "population"
    description := "The population dataset"
    collected := true
    struct := data_structure_of_population
  }

  // ...
\end{lstlisting}

\subsection{Using the IM artefacts}

Once the IM artefacts have been defined, the top-level VTL program can
import the corresponding IM instance using, for example:
\begin{lstlisting}
  import PopulationInfoModel::*
\end{lstlisting}

Then it can use the IM artefacts like, for instance:
\begin{lstlisting}
  define function make_histogram(input as population::t) {
    // ... do something ...
  }
\end{lstlisting}

Note that we are referring to the dataset type of the persistent
dataset as \texttt{population::t}.  That is the type which is mirrored
from \texttt{population::structure::t}.

Now that we have the dataset and the data structure objects in the
information model, whose structure is clearly defined with the
\texttt{System::MetaModel} types, we can access its field and inspect
its structure, and, possibly, feed these objects to \texttt{get} and
\texttt{put} methods.


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage

\appendix
\appendixpage

\section{Complete Type Syntax}
\label{sec:compl-synt-types}


  \noindent\<type> ::=
  \begin{syntdiag}
    % \begin{rep}
      \begin{rep}
        \begin{rep}
          \begin{stack}
            `null'
            \\
            <type-factor>
            \begin{stack}
              \\
              `?'
            \end{stack}
          \end{stack}
          \\
          `*'
        \end{rep}
      %   \\
      %   `|'
      % \end{rep}
      \\
      `->'
    \end{rep}
  \end{syntdiag}

  \noindent\<type-factor> ::=
  \begin{syntdiag}
    \begin{stack}
      `any'
      \\
      <scalar-type>
      \\
      <collection-type>
      \\
      <dataset-type>
      \\
      <module-type>
      \\
      `(' <type> `)'
      \\
      `none'
      % \\
      % `\textbf(' `\textbf)'
    \end{stack}
  \end{syntdiag}

  \noindent\<scalar-type> ::=
  \begin{syntdiag}
    \begin{stack}
      `scalar'
      \\
      `number'
      \\
      `integer'
      \begin{stack}
        \\
        `['
        \begin{stack}
          <int-literal>
          `:'
          \begin{stack}
          \\
          <int-literal>
          \end{stack}
          \\
          `:' <int-literal>
        \end{stack}
        `]'
        \\
        `{' \begin{rep} <int-literal> \\
            `,' \end{rep} `}'
      \end{stack}
      \\
      `float'
      \begin{stack}
        \\
        `['
        \begin{stack}
          <float-literal>
          `:'
          \begin{stack}
          \\
          <float-literal>
          \end{stack}
          \\
          `:' <float-literal>
        \end{stack}
        `]'
        \\
        `{' \begin{rep} <float-literal> \\
            `,' \end{rep} `}'
      \end{stack}
      \\
      `boolean'
      \begin{stack}
        \\
        `{'
          \begin{rep}
            \begin{stack}
              `true' \\ `false'
            \end{stack}
            \\
            `,'
          \end{rep}
          `}'
      \end{stack}
      \\
      `date'
      \\
      `string'
      \begin{stack}
        \\
        `[' <nat-literal>
        \begin{stack}
          \\
          `:' <nat-literal>
        \end{stack}
        `]'
        \\
        `{'
          \begin{rep}
            <string-literal>
            \\
            `,'
          \end{rep}
          `}'
      \end{stack}
      \\
      <qname>
    \end{stack}
  \end{syntdiag}

  \noindent\<collection-type> ::=
  \begin{syntdiag}
    \begin{stack}
      `collection' \\ `set' \\ `list'
    \end{stack}
    `<' <type> `>'
  \end{syntdiag}

  \noindent\<dataset-type> ::=
  \begin{syntdiag}
    `dataset'
    \begin{stack}
      \\
      <struct-spec>
    \end{stack}
  \end{syntdiag}

  \noindent\<struct-spec> ::=
  \begin{syntdiag}
    `{'
        \begin{rep}
%          <role>
          \begin{stack}
            `measure'
            \begin{stack}
              `_'
              \begin{stack}
                `*' \\ `+'
              \end{stack}
              \\
              <IDENT>
            \end{stack}
            \\
            \begin{stack}
              `identifier' \\ `attribute'
            \end{stack}
            <IDENT>
          \end{stack}
          `as' <scalar-type>
          \\
          `,'
        \end{rep}
        \begin{stack}
          \\
          `...'
        \end{stack}
      `}'
  \end{syntdiag}
  
  % \noindent\<role> ::=
  % \begin{syntdiag}
  %   \begin{stack}
  %     `identifier' \\ `measure' \\ `attribute'
  %   \end{stack}
  % \end{syntdiag}

  \noindent\<module-type> ::=
    \begin{syntdiag}
      `module'
      \begin{stack}
        \\
        \begin{stack}
          <signature>
          \\
          `type' <qname>
          \\
          `(' <type> `)'
        \end{stack}
      \begin{stack}
        \\
        \begin{rep}
          `with'
          \begin{stack}
            <signature>
            \\
            <qname>
            \\
            `module' `(' <type> `)'
          \end{stack}
          \\
        \end{rep}
      \end{stack}
      \end{stack}
  \end{syntdiag}

  \noindent\<signature> ::=
    \begin{syntdiag}
    `{'
      \begin{stack}
        \\
        \begin{rep}
          <import> \optSemiCol
          \\
        \end{rep}
      \end{stack}
      \begin{stack}
        \\
        \begin{rep}
         \begin{stack}
            <IDENT> `as' <type>
            \\
            `type' <IDENT>
            \begin{stack} `=' \\ `<:' \end{stack}
            <type>
          \end{stack}
          \optSemiCol
          \\
        \end{rep}
      \end{stack}
    `}'
  \end{syntdiag}


  \noindent\<import> ::=
  \begin{syntdiag}
    `import'
    <qname>
    \begin{stack}
      \\
      `as' <IDENT>
      \\
      `::'
      `{'
        \begin{stack}
          \\
          \begin{rep}
            <IDENT>
            \begin{stack}
              \\
              `as' <IDENT>
            \end{stack}
            \\
            `,'
          \end{rep}
        \end{stack}
        `}'
    \end{stack}
    \begin{stack}
      \\
      `from' <package-id> `:' <agency-id> `:' <version>
    \end{stack}
  \end{syntdiag}

  \noindent\<package-id>, \<agency-id>, \<version> ::=
  \<string-literal>
 
  \noindent\<qname> ::=
  \begin{syntdiag}
    % \begin{stack}
    %   \\
    %   `::'
    % \end{stack}
    \begin{rep}
	  <IDENT>
      \\
      `::'
    \end{rep}
  \end{syntdiag}

  % -----------------------------------------------------------------

  \section{Syntax for Top-Level Type Definitions}
  \label{sec:synt-type-defin}


  \noindent\<type-def> ::=
  \begin{syntdiag}
    `type' <IDENT> `=' <type> \optSemiCol
  \end{syntdiag}

  % -----------------------------------------------------------------

  \section{Syntax for Module Creation Expressions}
  \label{sec:synt-module-creat}

  \begin{syntdiag}
    `new'
    \begin{stack}
      `module'
      \\
      <qname>
    \end{stack}
    \begin{stack}
      \\
      `{'
        \begin{stack}
          \\
          \begin{rep}
            <import> \optSemiCol
            \\
          \end{rep}
        \end{stack}
        \begin{rep}
        \begin{stack}
          <IDENT> `:=' <expr>
          \\
          `type' <IDENT> `=' <type>
          % \\
          % `use' `module' <qname>
          % \begin{stack}
          %   \\
          %   `{' \begin{rep} <IDENT> \\ `,' \end{rep} `}'
          % \end{stack}
        \end{stack}
        \optSemiCol
        \\
      \end{rep}
      `}'
    \end{stack}
  \end{syntdiag}



\end{document}
